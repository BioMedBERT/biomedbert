{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Embeddings from Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from numpy.linalg import norm\n",
    "from invoke import run, exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_name = 'ekaba-assets'\n",
    "model_dir = 'biomedbert_large_bert_weights_and_vocab'\n",
    "config = 'large_bert_config.json'\n",
    "vocab = 'vocab.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.train.latest_checkpoint('gs://{}/{}'.format(bucket_name, model_dir))\n",
    "voc_fname = 'gs://{}/{}/{}'.format(bucket_name, model_dir, vocab)\n",
    "config_fname = 'gs://{}/{}/{}'.format(bucket_name, model_dir, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('biosaq_format.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>inheritance pattern li fraumeni syndrome</td>\n",
       "      <td>balanced q q tp breast cancer patient li fraum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>inheritance pattern li fraumeni syndrome</td>\n",
       "      <td>genetic modeling li fraumeni syndrome zebrafis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>type lung cancer afatinib used</td>\n",
       "      <td>clinical perspective afatinib non small cell l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hormone abnormalities characteristic pendred s...</td>\n",
       "      <td>doca sensitive pendrin expression kidney heart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hormone abnormalities characteristic pendred s...</td>\n",
       "      <td>clinical molecular characteristics pendred syn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0           inheritance pattern li fraumeni syndrome   \n",
       "1           inheritance pattern li fraumeni syndrome   \n",
       "2                     type lung cancer afatinib used   \n",
       "3  hormone abnormalities characteristic pendred s...   \n",
       "4  hormone abnormalities characteristic pendred s...   \n",
       "\n",
       "                                              answer  \n",
       "0  balanced q q tp breast cancer patient li fraum...  \n",
       "1  genetic modeling li fraumeni syndrome zebrafis...  \n",
       "2  clinical perspective afatinib non small cell l...  \n",
       "3  doca sensitive pendrin expression kidney heart...  \n",
       "4  clinical molecular characteristics pendred syn...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to .txt file\n",
    "def series_to_file(series, fname):\n",
    "    series.to_csv('{}.txt'.format(fname), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "series_to_file(data.question, 'question')\n",
    "series_to_file(data.answer, 'answer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ekaba-assets/biomedbert_large_bert_weights_and_vocab/model.ckpt-1000000\n",
      "gs://ekaba-assets/biomedbert_large_bert_weights_and_vocab/vocab.txt\n",
      "gs://ekaba-assets/biomedbert_large_bert_weights_and_vocab/large_bert_config.json\n"
     ]
    }
   ],
   "source": [
    "print(checkpoint)\n",
    "print(voc_fname)\n",
    "print(config_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer.txt\n",
      "output_answer.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_name = os.path.relpath('answer.txt')\n",
    "output_dir = 'output_{}.jsonl'.format(file_name.split('.')[0])\n",
    "print(file_name)\n",
    "print(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 bert/extract_features.py \\\n",
    "--input_file={file_name} \\\n",
    "--output_file={output_dir} \\\n",
    "--vocab_file={voc_fname} \\\n",
    "--bert_config_file={config_fname} \\\n",
    "--init_checkpoint={checkpoint} \\\n",
    "--layers=-1 \\ #,-2,-3,-4 \\\n",
    "--max_seq_length=128 \\\n",
    "--batch_size=8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format outout JSONl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_dir) as f:\n",
    "    data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_embed(output_jsonl) :\n",
    "    #We will run the model and get the outputs\n",
    "    json_lines = output_jsonl.split('\\n')\n",
    "    \n",
    "    #Removing the blank strings\n",
    "    json_lines =  list(filter(None,json_lines))\n",
    "    \n",
    "    #getting the dimensions & getting the output of the query\n",
    "    line_q = json.loads(json_lines[0])\n",
    "    embed_size = len(line_q['features'][0]['layers'][0]['values'])\n",
    "    \n",
    "    #Temp list for saving the tokens\n",
    "    token_temp_q = []\n",
    "    \n",
    "    #array for saving the embeddings\n",
    "    feat_embed_q =  np.array(line_q['features'][0]['layers'][0]['values'])\n",
    "    \n",
    "    #Getting the final df\n",
    "    df_query = pd.DataFrame()\n",
    "    \n",
    "    for j,feature in enumerate(line_q['features']):\n",
    "        token_temp_q.append(feature['token'])\n",
    "\n",
    "\n",
    "    #final_output_embeddings\n",
    "    tokens_query = ' '.join(token_temp_q[1:len(token_temp_q)-1])\n",
    "\n",
    "    #final query dataframe\n",
    "    df_query['documents'] = [tokens_query]\n",
    "    df_query['embedding'] = [feat_embed_q]\n",
    "    \n",
    "    \n",
    "    #--------------------------------------- answers ----------------------------------------------#\n",
    "    \n",
    "    \n",
    "    #Defining the lists\n",
    "    sent_embed = []\n",
    "    tokens = []\n",
    "    \n",
    "    #Getting the final df\n",
    "    df_ans = pd.DataFrame()\n",
    "    \n",
    "    #Running for the sentence\n",
    "    for i in range(1,len(json_lines)):\n",
    "        line = json.loads(json_lines[i])        \n",
    "    \n",
    "        feat_embed = np.array(line['features'][0]['layers'][0]['values'])\n",
    "        \n",
    "        #Temp list for saving the tokens\n",
    "        token_temp = []\n",
    "        \n",
    "        for j,feature in enumerate(line['features']):\n",
    "            token_temp.append(feature['token'])\n",
    "            \n",
    "        \n",
    "        #sanity checks\n",
    "        if feat_embed.sum() == 0 :\n",
    "            print ('Check_model')\n",
    "        \n",
    "        #final_output_embeddings\n",
    "        sent_embed.append(feat_embed)\n",
    "        tokens.append(' '.join(token_temp[1:len(token_temp)-1]))\n",
    "        \n",
    "         \n",
    "        \n",
    "    df_ans['documents'] = tokens\n",
    "    df_ans['embedding'] = sent_embed\n",
    "    \n",
    "    return df_query, df_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 1.66 s, total: 1min 15s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_query, df_ans = get_sent_embed(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>balanced q q t ##p breast cancer patient l ##i...</td>\n",
       "      <td>[0.506378, 0.714099, -0.343656, -1.102875, -1....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           documents  \\\n",
       "0  balanced q q t ##p breast cancer patient l ##i...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.506378, 0.714099, -0.343656, -1.102875, -1....  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>genetic modeling l ##i f ##ra ##ume ##ni syndr...</td>\n",
       "      <td>[-0.476865, 0.976585, 0.59813, -0.45718, -0.93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clinical perspective a ##fa ##tin ##ib non sma...</td>\n",
       "      <td>[0.032693, 1.321281, 0.742127, -1.232175, -0.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>do ##ca sensitive pen ##dr ##in expression kid...</td>\n",
       "      <td>[-0.034027, 1.207761, 1.166138, -0.48594, -1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>clinical molecular characteristics pen ##dre #...</td>\n",
       "      <td>[-0.59723, 1.333176, 0.339485, -0.107071, -0.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pen ##dre ##d syndrome t ##uni ##sia objective...</td>\n",
       "      <td>[-0.020153, -0.491783, -0.226507, -0.491128, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           documents  \\\n",
       "0  genetic modeling l ##i f ##ra ##ume ##ni syndr...   \n",
       "1  clinical perspective a ##fa ##tin ##ib non sma...   \n",
       "2  do ##ca sensitive pen ##dr ##in expression kid...   \n",
       "3  clinical molecular characteristics pen ##dre #...   \n",
       "4  pen ##dre ##d syndrome t ##uni ##sia objective...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.476865, 0.976585, 0.59813, -0.45718, -0.93...  \n",
       "1  [0.032693, 1.321281, 0.742127, -1.232175, -0.8...  \n",
       "2  [-0.034027, 1.207761, 1.166138, -0.48594, -1.0...  \n",
       "3  [-0.59723, 1.333176, 0.339485, -0.107071, -0.8...  \n",
       "4  [-0.020153, -0.491783, -0.226507, -0.491128, -...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_ans.embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ans.to_pickle('answer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
