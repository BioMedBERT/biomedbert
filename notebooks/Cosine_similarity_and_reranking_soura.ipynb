{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import cosine as cs\n",
    "from numpy.linalg import norm\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_data(input_path) :\n",
    "    with open(input_path) as fin:\n",
    "        inp = fin.read()\n",
    "        inp_list = inp.split('\\n')\n",
    "        inp_list = list(filter(None, inp_list))\n",
    "\n",
    "    return inp,inp_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/s0c02nj/Downloads/covid-19_research_collaboration-master/notebooks/output_fra.jsonl') as fin:\n",
    "    output_jsonl = fin.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_embed(input_path, output_jsonl) :\n",
    "    \n",
    "    document,list_doc = get_input_data(input_path)\n",
    "    \n",
    "    #We will run the model and get the outputs\n",
    "    model_output = output_jsonl\n",
    "    json_lines = model_output.split('\\n')\n",
    "    \n",
    "    #getting the dimensions\n",
    "    embed_size = 768\n",
    "    \n",
    "    #Defining the lists\n",
    "    sent_embed = []\n",
    "    tokens = []\n",
    "    \n",
    "    #Getting the final df\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    #Running for the sentence\n",
    "    for i in range(0,len(list_doc)):\n",
    "        line = json.loads(json_lines[i])\n",
    "        \n",
    "        #array for saving the embeddings\n",
    "        feat_embed = np.zeros((len(line['features']),embed_size))\n",
    "        \n",
    "        #Temp list for saving the tokens\n",
    "        token_temp = []\n",
    "        for j,feature in enumerate(line['features']):\n",
    "            \n",
    "            token_temp.append(feature['token'])\n",
    "            feat_embed[j] = feature['layers'][0]['values']\n",
    "        \n",
    "        #sanity checks\n",
    "        avg_embed =  np.mean(feat_embed[1:len(feat_embed)-1],axis=0)\n",
    "        if avg_embed.sum() == 0 :\n",
    "            print ('Check_model')\n",
    "        \n",
    "        #final_output_embeddings\n",
    "        sent_embed.append(avg_embed)\n",
    "        tokens.append(' '.join(token_temp[1:len(token_temp)-1]))\n",
    "        \n",
    "         \n",
    "        \n",
    "    df['documents'] = tokens\n",
    "    df['embedding'] = sent_embed\n",
    "    \n",
    "    return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ans = '/Users/s0c02nj/Downloads/covid-19_research_collaboration-master/notebooks/answers.txt'\n",
    "\n",
    "input_query = '/Users/s0c02nj/Downloads/covid-19_research_collaboration-master/notebooks/question.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is the first sentence'"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query['documents'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_sim(input_ans, input_query ,output_jsonl, topk) :\n",
    "    \n",
    "    #We will run the model and get the outputs\n",
    "    model_output = output_jsonl\n",
    "    \n",
    "    #Getting the dataframes\n",
    "    df_query = get_sent_embed(input_query, model_output)\n",
    "    df_ans =   get_sent_embed(input_ans, model_output)\n",
    "    \n",
    "    \n",
    "    #Query embedding\n",
    "    query_embed = df_query['embedding'].values[0]\n",
    "    query_embed_norm = query_embed/norm(query_embed)\n",
    "    \n",
    "    #Answers embedding\n",
    "    list_embed = df_ans['embedding'].tolist()\n",
    "    \n",
    "    #getting the answer embedding\n",
    "    ans_embed =  np.stack(list_embed, axis=0)\n",
    "    ans_embed_norm = ans_embed/norm(ans_embed,axis=1,keepdims= True)\n",
    "    \n",
    "    cos_sim = np.dot(ans_embed_norm,query_embed_norm)\n",
    "    \n",
    "    \n",
    "    #Output Format\n",
    "    df_out = pd.DataFrame()\n",
    "    df_out['answers'] = df_ans['documents'].tolist()\n",
    "    df_out['similarity'] = cos_sim\n",
    "    df_out['Query'] = df_query['documents'].values[0]\n",
    "    \n",
    "    #Output sorted\n",
    "    final_df = df_out.sort_values(by=['similarity'], ascending=False)[['Query','answers','similarity']]\n",
    "\n",
    "    \n",
    "    return final_df.head(topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = get_cosine_sim(input_ans, input_query ,output_jsonl, topk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>answers</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is the first sentence</td>\n",
       "      <td>this is the first sentence</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is the first sentence</td>\n",
       "      <td>this is the second sentence</td>\n",
       "      <td>0.951076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is the first sentence</td>\n",
       "      <td>this is the third sentence</td>\n",
       "      <td>0.948371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is the first sentence</td>\n",
       "      <td>this is not the third sentence</td>\n",
       "      <td>0.882423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is the first sentence</td>\n",
       "      <td>the sky is blue this morning</td>\n",
       "      <td>0.399714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Query                         answers  similarity\n",
       "0  this is the first sentence      this is the first sentence    1.000000\n",
       "1  this is the first sentence     this is the second sentence    0.951076\n",
       "2  this is the first sentence      this is the third sentence    0.948371\n",
       "3  this is the first sentence  this is not the third sentence    0.882423\n",
       "4  this is the first sentence    the sky is blue this morning    0.399714"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
