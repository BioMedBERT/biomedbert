{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from numpy.linalg import norm\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the first sentence.This is a nice day.Good day.I am not sure why.\n",
      "This is the second sentence.This is not the first sentence. We know that.\n",
      "This is the third sentence.This is not the first sentence.This is not the first sentence.\n",
      "This is not the third sentence.We know that.\n",
      "The sky is blue this morning. It was not like this yesterday.\n"
     ]
    }
   ],
   "source": [
    "with open('./input_answers.txt') as fin:\n",
    "    inp = fin.read()\n",
    "    print(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biomedbert code extract embeddings \"./input_answers.txt\" \n",
    "# \"gs://ekaba-assets/bert_model_sat_18th_april/biomedbert-8M.txt\" \n",
    "# \"gs://ekaba-assets/bert_model_sat_18th_april/bert_config.json\" \n",
    "# \"gs://ekaba-assets/bert_model_sat_18th_april/model.ckpt-1000000\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'outputinput_answers.jsonl'\n",
    "\n",
    "with open('outputinput_answers.jsonl') as fin:\n",
    "    output_jsonl = fin.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sent_embed(output_jsonl) :\n",
    "    \n",
    "    #We will run the model and get the outputs\n",
    "    json_lines = output_jsonl.split('\\n')\n",
    "    \n",
    "    #Removing the blank strings\n",
    "    json_lines =  list(filter(None,json_lines))\n",
    "    \n",
    "    #getting the dimensions & getting the output of the query\n",
    "    line_q = json.loads(json_lines[0])\n",
    "    embed_size = len(line_q['features'][0]['layers'][0]['values'])\n",
    "    \n",
    "    #Temp list for saving the tokens\n",
    "    token_temp_q = []\n",
    "    \n",
    "    #array for saving the embeddings\n",
    "    feat_embed_q = np.zeros((len(line_q['features']),embed_size))\n",
    "    \n",
    "    #Getting the final df\n",
    "    df_query = pd.DataFrame()\n",
    "    \n",
    "    for j,feature in enumerate(line_q['features']):\n",
    "        \n",
    "        if feature['token'] != '[UNK]':\n",
    "            token_temp_q.append(feature['token'])\n",
    "            feat_embed_q[j] = feature['layers'][0]['values']\n",
    "\n",
    "\n",
    "    #mean_embed\n",
    "    avg_embed_q =  np.mean(feat_embed_q[1:len(feat_embed_q)-1],axis=0)\n",
    "    \n",
    "    #final_output_embeddings\n",
    "    tokens_query = ' '.join(token_temp_q[1:len(token_temp_q)-1])\n",
    "\n",
    "    #final query dataframe\n",
    "    df_query['documents'] = [tokens_query]\n",
    "    df_query['embedding'] = [avg_embed_q]\n",
    "    \n",
    "    \n",
    "    #--------------------------------------- answers ----------------------------------------------#\n",
    "    \n",
    "    #Defining the lists\n",
    "    sent_embed = []\n",
    "    tokens = []\n",
    "    \n",
    "    #Getting the final df\n",
    "    df_ans = pd.DataFrame()\n",
    "    \n",
    "    #Running for the sentence\n",
    "    for i in range(1,len(json_lines)):\n",
    "        line = json.loads(json_lines[i])\n",
    "        \n",
    "        #array for saving the embeddings\n",
    "        feat_embed = np.zeros((len(line['features']),embed_size))\n",
    "        \n",
    "        #Temp list for saving the tokens\n",
    "        token_temp = []\n",
    "        for j,feature in enumerate(line['features']):\n",
    "            \n",
    "            if feature['token'] != '[UNK]':\n",
    "                token_temp.append(feature['token'])\n",
    "                feat_embed[j] = feature['layers'][0]['values']\n",
    "            \n",
    "\n",
    "        #sanity checks\n",
    "        avg_embed =  np.mean(feat_embed[1:len(feat_embed)-1],axis=0)\n",
    "\n",
    "        \n",
    "        #final_output_embeddings\n",
    "        sent_embed.append(avg_embed)\n",
    "        tokens.append(' '.join(token_temp[1:len(token_temp)-1]))\n",
    "        \n",
    "         \n",
    "        \n",
    "    df_ans['documents'] = tokens\n",
    "    df_ans['embedding'] = sent_embed\n",
    "    \n",
    "    return df_query ,df_ans\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_sim(output_jsonl) :\n",
    "    \n",
    "    #We will run the model and get the outputs\n",
    "    \n",
    "    #Getting the dataframes\n",
    "    df_query ,df_ans = get_sent_embed(output_jsonl)\n",
    "    \n",
    "    #Query embedding\n",
    "    query_embed = df_query['embedding'].values[0]\n",
    "    query_embed_norm = query_embed/norm(query_embed)\n",
    "    \n",
    "    #Answers embedding\n",
    "    list_embed = df_ans['embedding'].tolist()\n",
    "    \n",
    "    #getting the answer embedding\n",
    "    ans_embed =  np.stack(list_embed, axis=0)\n",
    "    ans_embed_norm = ans_embed/norm(ans_embed,axis=1,keepdims= True)\n",
    "    \n",
    "    #find the cosine similarity\n",
    "    cos_sim = np.dot(ans_embed_norm,query_embed_norm)\n",
    "    \n",
    "    return cos_sim.argsort()[::-1],np.sort(cos_sim)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query ,df_ans = get_sent_embed(output_jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind,scores = get_cosine_sim(output_jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 2, 1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.80510926, 0.76211442, 0.74950555, 0.7376297 ])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is the first sentence this is a nice day ...</td>\n",
       "      <td>[0.07916590476190477, -0.2536499523809524, 0.1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           documents  \\\n",
       "0  this is the first sentence this is a nice day ...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.07916590476190477, -0.2536499523809524, 0.1...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>documents</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>this is the second sentence this is not the fi...</td>\n",
       "      <td>[0.09111094117647064, -0.372554, 0.01575058823...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is the third sentence this is not the fir...</td>\n",
       "      <td>[0.15030149999999995, -0.11581355000000002, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>this is not the third sentence we know that</td>\n",
       "      <td>[-0.2963907272727273, -0.4580452727272728, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the sky is blue this morning it was not like t...</td>\n",
       "      <td>[0.530984625, -0.535006125, 0.540343375, -0.45...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           documents  \\\n",
       "0  this is the second sentence this is not the fi...   \n",
       "1  this is the third sentence this is not the fir...   \n",
       "2        this is not the third sentence we know that   \n",
       "3  the sky is blue this morning it was not like t...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.09111094117647064, -0.372554, 0.01575058823...  \n",
       "1  [0.15030149999999995, -0.11581355000000002, -0...  \n",
       "2  [-0.2963907272727273, -0.4580452727272728, -0....  \n",
       "3  [0.530984625, -0.535006125, 0.540343375, -0.45...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
