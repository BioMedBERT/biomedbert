{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab.auth import authenticate_user\n",
    "authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp gs://ekaba-assets/datasets/QA/BioASQ/BioASQ-train-factoid-4b.json .\n",
    "!gsutil cp gs://ekaba-assets/datasets/QA/BioASQ/BioASQ-train-factoid-5b.json .\n",
    "!gsutil cp gs://ekaba-assets/datasets/QA/BioASQ/BioASQ-train-factoid-6b.json .\n",
    "!gsutil cp gs://ekaba-assets/datasets/QA/BioASQ/training7b.json ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('BioASQ-train-factoid-4b.json')\n",
    "df2 = pd.read_json('BioASQ-train-factoid-5b.json')\n",
    "df3 = pd.read_json('BioASQ-train-factoid-6b.json')\n",
    "df4 = pd.read_json('training7b.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = len(df1['data'].iloc[0]['paragraphs'])\n",
    "l2 = len(df2['data'].iloc[0]['paragraphs'])\n",
    "l3 = len(df3['data'].iloc[0]['paragraphs'])\n",
    "l4 = len(df4['data'].iloc[0]['paragraphs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(l,df) :\n",
    "\n",
    "    question = []\n",
    "    q_id = []\n",
    "    ans = []\n",
    "\n",
    "    for i in tqdm(range(0,l)):\n",
    "\n",
    "        para = df['data'].iloc[0]['paragraphs'][i]\n",
    "        qas = para['qas'][0]\n",
    "\n",
    "        question.append(qas['question'])\n",
    "        q_id.append(qas['id'])\n",
    "        ans.append(para['context'])\n",
    "        \n",
    "    \n",
    "    \n",
    "    #Dataframe\n",
    "    df_qa = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    #dataframe\n",
    "    df_qa['id'] = q_id\n",
    "    df_qa['question'] = question\n",
    "    df_qa['answer'] = ans\n",
    "\n",
    "    return df_qa\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa1 = get_df(l1,df1)\n",
    "df_qa2 = get_df(l2,df2)\n",
    "df_qa3 = get_df(l3,df3)\n",
    "df_qa4 = get_df(l4,df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa = pd.concat([df_qa1,df_qa2,df_qa3,df_qa4],sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa = df_qa.drop(['id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa['answer'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa_un = df_qa.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa_un.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    text= text.lower()\n",
    "    text= re.sub(r'[^a-z]',' ',text)\n",
    "    #text= \" \".join([s for s in text.split() if len(s)>2])\n",
    "    #text= \" \".join([x for x in text.split() if x not in stopwords.words('english')])\n",
    "    #text= \" \".join([inflection.singularize(x) for x in text.split()])\n",
    "    text= text.strip()\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa_un['question'] = df_qa_un['question'].progress_apply(lambda x: text_preprocessing(x))\n",
    "df_qa_un['answer'] =   df_qa_un['answer'].progress_apply(lambda x: text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_qa_un.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ques = list(df_qa_un['question'].unique())\n",
    "unique_ans =  list(df_qa_un['answer'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ques = {}\n",
    "\n",
    "for i,qs in enumerate(unique_ques):\n",
    "    dict_ques[qs] = i    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ans = {}\n",
    "\n",
    "for i,ans in enumerate(unique_ans):\n",
    "    dict_ans[ans] = i    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qid = []\n",
    "pid = []\n",
    "\n",
    "\n",
    "for i in tqdm(range(0,len(df_qa_un))):\n",
    "    \n",
    "    ques = df_qa_un['question'].iloc[i]\n",
    "    ans = df_qa_un['answer'].iloc[i]\n",
    "    \n",
    "    qid.append(dict_ques[ques])\n",
    "    pid.append(dict_ans[ans])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa_un['qid'] = qid\n",
    "df_qa_un['pid'] = pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa_un.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa_un[df_qa_un['answer'].str.contains('fraumeni')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa_un[df_qa_un['answer'].str.contains('status')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_qa1['qid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_qa1['pid'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to have more answers per question to have a more robust MRR metric. We will add more data synthetically to enhance the quality of the metric"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
