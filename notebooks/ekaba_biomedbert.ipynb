{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E08w9hc0TAbI"
   },
   "source": [
    "# BioMedBERT BigQuery Data Analysis/ Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zmQTSz_7Sy30"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "import tensorflow as tf\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I348xIulUEnV"
   },
   "outputs": [],
   "source": [
    "project_id = 'ai-vs-covid19'\n",
    "client = bigquery.Client(project=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gL4YG5N6Tn61"
   },
   "source": [
    "## Query Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "HvHzfvtKT6c9",
    "outputId": "c2e55ef1-3886-49b5-e4d0-2be6083d4926"
   },
   "outputs": [],
   "source": [
    "# Get number of rows\n",
    "row_count = client.query('''\n",
    "  SELECT \n",
    "    COUNT(*) as total\n",
    "  FROM `ai-vs-covid19.BigBioMedBERT2.ncbi_comm_use`''').to_dataframe().total\n",
    "row_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "7urYHJj7UZXX",
    "outputId": "08e96a86-7ac0-42ea-97c3-ba93f9684512"
   },
   "outputs": [],
   "source": [
    "# get column names\n",
    "col_names = client.query('''\n",
    "  SELECT column_name\n",
    "  FROM `ai-vs-covid19.BigBioMedBERT2`.INFORMATION_SCHEMA.COLUMNS\n",
    "  WHERE table_name = 'ncbi_comm_use'\n",
    "''').to_dataframe()\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "8nEHxJIhVUOl",
    "outputId": "4408561d-0ef4-4305-c4e1-181205b32193"
   },
   "outputs": [],
   "source": [
    "# get general table information schema\n",
    "table_schema = client.query('''\n",
    "  SELECT *\n",
    "  FROM `ai-vs-covid19.BigBioMedBERT2`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS\n",
    "  WHERE table_name = 'ncbi_comm_use'\n",
    "''').to_dataframe()\n",
    "table_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "colab_type": "code",
    "id": "eDhjuF80V8pl",
    "outputId": "a223c11e-1201-403b-820f-4fd1adaa5f15"
   },
   "outputs": [],
   "source": [
    "# select first 10 rows\n",
    "first_10_rows = client.query('''\n",
    "  SELECT *\n",
    "  FROM `ai-vs-covid19.BigBioMedBERT2.ncbi_comm_use`\n",
    "  LIMIT 10\n",
    "''').to_dataframe()\n",
    "first_10_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YtA3hlOcWpsW"
   },
   "outputs": [],
   "source": [
    "# print body text\n",
    "def print_body(body_series: pd.Series) -> str:\n",
    "  print(textwrap.fill(body_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "0up3UTnLW1kA",
    "outputId": "1d7af912-bc5b-4af1-90fd-088254208795"
   },
   "outputs": [],
   "source": [
    "print_body(first_10_rows.Body[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i6qIv0aCfioQ"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "zo9iWkzrfzM9",
    "outputId": "d21cbd0c-aecc-4e4c-8c54-f6c2dc6122c9"
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece\n",
    "# !git clone https://github.com/google-research/bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_k54abHhhGP3"
   },
   "outputs": [],
   "source": [
    "# base imports\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "XOj-PvpHd0SC",
    "outputId": "bc809857-8cde-4017-aec4-926b446848aa"
   },
   "outputs": [],
   "source": [
    "#import bert modules\n",
    "sys.path.append(\"bert\")\n",
    "from bert import modeling, optimization, tokenization\n",
    "from bert.run_pretraining import input_fn_builder, model_fn_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0Vw0rZIhsqI"
   },
   "source": [
    "### Preprocess text\n",
    "Remove punсtuation, uppercase letters and non-utf symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QLnaz54Pg13C"
   },
   "outputs": [],
   "source": [
    "regex_tokenizer = nltk.RegexpTokenizer(\"\\w+\")\n",
    "\n",
    "def normalize_text(text):\n",
    "  # lowercase text\n",
    "  text = str(text).lower()\n",
    "  # remove non-UTF\n",
    "  text = text.encode(\"utf-8\", \"ignore\").decode()\n",
    "  # remove punctuation symbols\n",
    "  text = \" \".join(regex_tokenizer.tokenize(text))\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vJ9M2-aYiAXb",
    "outputId": "b462ab03-011e-44ff-e743-0a62c58729fa"
   },
   "outputs": [],
   "source": [
    "# example to normalize text from ``Body`` in BioMedBERT dataset\n",
    "print_body(normalize_text(first_10_rows.Body[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fk8rgWTLGoXT"
   },
   "source": [
    "## Create Expanded csv dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LOiLn33dPPbl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IbunQH1_SWWc"
   },
   "outputs": [],
   "source": [
    "storage_client = storage.Client(project=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1tpbvp2ASAjC"
   },
   "outputs": [],
   "source": [
    "bucket=storage_client.get_bucket('big_bio_med_bert_dump_csv')\n",
    "# List all objects that satisfy the filter.\n",
    "blobs=bucket.list_blobs(prefix='ncbi_comm_use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8pAaD8geSAmS"
   },
   "outputs": [],
   "source": [
    "blob = [blob for blob in blobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "WHy-ysLfnozM",
    "outputId": "aff1f76f-db54-4112-82ae-869c601603c7"
   },
   "outputs": [],
   "source": [
    "print(len(blob))\n",
    "print(len(blob) // 5)\n",
    "print((len(blob) // 5)*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f9pcw0ZhTas1"
   },
   "outputs": [],
   "source": [
    "# Create a function called \"chunks\" with two arguments, l and n:\n",
    "def split_list(data, chunk):\n",
    "    # For item i in a range that is a length of data (l),\n",
    "    for i in range(0, len(data), chunk):\n",
    "        # Create an index range for data of chunk (e.g. 5) items:\n",
    "        yield data[i:i+chunk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oi-tMaehoGZf"
   },
   "outputs": [],
   "source": [
    "# list of length in which we have to split \n",
    "blob_split_1, blob_split_2, blob_split_3, blob_split_4, blob_split_5 = list(split_list(blob, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "NMr8VEj8TbG9",
    "outputId": "ba4d3303-a2ad-4552-bae6-5dbc628d6ada"
   },
   "outputs": [],
   "source": [
    "print(len(blob))\n",
    "print(len(blob_split_1))\n",
    "print(len(blob_split_2))\n",
    "print(len(blob_split_3))\n",
    "print(len(blob_split_4))\n",
    "print(len(blob_split_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "-MakXh7v31xU",
    "outputId": "631dac94-aad5-4927-860b-765a3dc29695"
   },
   "outputs": [],
   "source": [
    "blob_split_1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "7eqOehVw4Lhh",
    "outputId": "2efffffb-8d4f-40a7-db40-a6a300770e51"
   },
   "outputs": [],
   "source": [
    "blob_split_2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-dXTAMgTur6"
   },
   "outputs": [],
   "source": [
    "def download_to_local(folder, blob_lst):\n",
    "    print('File download Started…. Wait for the job to complete.')\n",
    "    # Create this folder locally if not exists\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    # Iterating through for loop one by one using API call\n",
    "    for blob in blob_lst:\n",
    "#         print('Blobs: {}'.format(blob.name))\n",
    "        destination_uri = '{}/{}'.format(folder, (blob.name).split('/')[-1])\n",
    "        blob.download_to_filename(destination_uri)\n",
    "        print('Exported {} to {}'.format(blob.name, destination_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g-CWG7n41_5x"
   },
   "outputs": [],
   "source": [
    "# !rm -rf data #data_1 data_2 data_3 data_4 #data_5\n",
    "# !rm ncbi_comm_use_csv_A.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "S-luesxCT4uT",
    "outputId": "9ab6d42e-49c5-4fd2-abcf-38fd510e3ea3"
   },
   "outputs": [],
   "source": [
    "# download first part of csv's\n",
    "# download_to_local('data', blob)\n",
    "# download_to_local('data_1', blob_split_1)\n",
    "# download_to_local('data_2', blob_split_2)\n",
    "# download_to_local('data_3', blob_split_3)\n",
    "# download_to_local('data_4', blob_split_4)\n",
    "# download_to_local('data_5', blob_split_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96PJ6YMXT4xY"
   },
   "outputs": [],
   "source": [
    "# make combined csv\n",
    "def combined_csv(data_folder):\n",
    "    extension = 'csv'\n",
    "    all_filenames = [i for i in glob.glob('{}/*.{}'.format(data_folder, extension))]\n",
    "    #combine all files in the list\n",
    "    combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "    return combined_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zdBDgQhnUrsp"
   },
   "outputs": [],
   "source": [
    "# blob_csv_A = combined_csv('data')\n",
    "# blob_csv = combined_csv('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dBVxTfO2Urqm",
    "outputId": "92f57f11-69db-493d-b367-099115c2ee0b"
   },
   "outputs": [],
   "source": [
    "# len(blob_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FX9RsVjKbc_Z"
   },
   "outputs": [],
   "source": [
    "# blob_csv.to_csv('gs://ekaba-assets/ncbi_comm_use.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9udoWp5weDq0"
   },
   "outputs": [],
   "source": [
    "# blob_csv_A.to_csv( \"ncbi_comm_use_csv_A.csv\", index=False, encoding='utf-8-sig')\n",
    "# blob_csv.to_csv( \"ncbi_comm_use.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OsbTPI7aGmQs"
   },
   "outputs": [],
   "source": [
    "# copy files from gcs bucket\n",
    "# !gsutil -m cp gs://ekaba-assets/ncbi_comm_use_BODY.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ad8s14h8QL4d"
   },
   "outputs": [],
   "source": [
    "# body = pd.read_csv('ncbi_comm_use.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body_sel = body[['Body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body_sel.to_csv('gs://ekaba-assets/ncbi_comm_use_BODY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body_sel.to_csv( \"ncbi_comm_use_BODY.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove FULL ncbi_comm_use.csv\n",
    "# !rm ncbi_comm_use.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nRTgOh2UQL0M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YOWtq2VJq2m7"
   },
   "outputs": [],
   "source": [
    "# convert csv to txt\n",
    "import csv\n",
    "import sys\n",
    "maxInt = sys.maxsize\n",
    "csv.field_size_limit(maxInt)\n",
    "\n",
    "csv_file = 'ncbi_comm_use_BODY.csv'\n",
    "txt_file = 'ncbi_comm_use_BODY.txt'\n",
    "with open(txt_file, \"w\") as my_output_file:\n",
    "    with open(csv_file, \"r\") as my_input_file:\n",
    "        [ my_output_file.write(\" \".join(row)+'\\n') for row in csv.reader(my_input_file)]\n",
    "    my_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move text file to GCS\n",
    "# !gsutil -m cp ncbi_comm_use_BODY.txt gs://ekaba-assets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove csv file\n",
    "# !rm ncbi_comm_use_BODY.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8xAPAIXtspSk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Progbar\n",
    "def count_lines(filename):\n",
    "  count = 0\n",
    "  with open(filename) as fi:\n",
    "    for line in fi:\n",
    "      count += 1\n",
    "  return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lnyso68uBp8r",
    "outputId": "a23ada36-710c-4099-b07b-145e7e03aa19"
   },
   "outputs": [],
   "source": [
    "# Apply normalization to entire dataset\n",
    "RAW_DATA_FPATH = \"ncbi_comm_use_BODY.txt\"\n",
    "PRC_DATA_FPATH = \"processed_ncbi_comm_use_BODY.txt\"\n",
    "\n",
    "# apply normalization to the dataset\n",
    "\n",
    "total_lines = count_lines(RAW_DATA_FPATH)\n",
    "bar = Progbar(total_lines)\n",
    "\n",
    "with open(RAW_DATA_FPATH,encoding=\"utf-8\") as fi:\n",
    "  with open(PRC_DATA_FPATH, \"w\",encoding=\"utf-8\") as fo:\n",
    "    for l in fi:\n",
    "      fo.write(normalize_text(l)+\"\\n\")\n",
    "      bar.add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move processed text file to GCS\n",
    "# !gsutil -m cp processed_ncbi_comm_use_BODY.txt gs://ekaba-assets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove intermediate files\n",
    "# !rm ncbi_comm_use_BODY.csv ncbi_comm_use_BODY.txt #processed_ncbi_comm_use_BODY.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3QSqf2hLpk6d"
   },
   "source": [
    "## Building the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRC_DATA_FPATH = \"processed_ncbi_comm_use_BODY.txt\"\n",
    "MODEL_PREFIX = \"biomedbert\" #@param {type: \"string\"}\n",
    "VOC_SIZE = 32000 #@param {type:\"integer\"}\n",
    "SUBSAMPLE_SIZE = 12800000 #@param {type:\"integer\"}\n",
    "NUM_PLACEHOLDERS = 256 #@param {type:\"integer\"}\n",
    "\n",
    "SPM_COMMAND = ('--input={} --model_prefix={} '\n",
    "               '--vocab_size={} --input_sentence_size={} '\n",
    "               '--shuffle_input_sentence=true ' \n",
    "               '--bos_id=-1 --eos_id=-1').format(\n",
    "               PRC_DATA_FPATH, MODEL_PREFIX, \n",
    "               VOC_SIZE - NUM_PLACEHOLDERS, SUBSAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TUgPWa78sDjx",
    "outputId": "946a4f79-56d7-4182-896a-214bd95fa0e0"
   },
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.Train(SPM_COMMAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "0zMTm7QJsdvQ",
    "outputId": "2e5ba2d6-1e11-4733-98e1-abc64d942953"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "91Vla2Ivx2S4",
    "outputId": "f0c7ee08-7b06-4f41-ff5d-9249ed0294ca"
   },
   "outputs": [],
   "source": [
    "!head -n 30 tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2skaOTxux5Xq"
   },
   "outputs": [],
   "source": [
    "def read_sentencepiece_vocab(filepath):\n",
    "  voc = []\n",
    "  with open(filepath, encoding='utf-8') as fi:\n",
    "    for line in fi:\n",
    "      voc.append(line.split(\"\\t\")[0])\n",
    "  # skip the first <unk> token\n",
    "  voc = voc[1:]\n",
    "  return voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "2u0i7LeJAmnO",
    "outputId": "3195d499-ff7a-4453-c41d-1bc51f685c0b"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "snt_vocab = read_sentencepiece_vocab(\"{}.vocab\".format(MODEL_PREFIX))\n",
    "print(\"Learnt vocab size: {}\".format(len(snt_vocab)))\n",
    "print(\"Sample tokens: {}\".format(random.sample(snt_vocab, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mCW9uiQMAw1G"
   },
   "outputs": [],
   "source": [
    "def parse_sentencepiece_token(token):\n",
    "    if token.startswith(\"▁\"):\n",
    "        return token[1:]\n",
    "    else:\n",
    "        return \"##\" + token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cq3ArCOvA4kV"
   },
   "outputs": [],
   "source": [
    "bert_vocab = list(map(parse_sentencepiece_token, snt_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hy-jY1pQA7aO"
   },
   "outputs": [],
   "source": [
    "ctrl_symbols = [\"[PAD]\",\"[UNK]\",\"[CLS]\",\"[SEP]\",\"[MASK]\"]\n",
    "bert_vocab = ctrl_symbols + bert_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gdq1IFoGBEAq",
    "outputId": "984065a5-f5f1-4afe-8102-0983161bc16f"
   },
   "outputs": [],
   "source": [
    "bert_vocab += [\"[UNUSED_{}]\".format(i) for i in range(VOC_SIZE - len(bert_vocab))]\n",
    "print(len(bert_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQHKGBCYBF5_"
   },
   "outputs": [],
   "source": [
    "# write vocabulary to file\n",
    "VOC_FNAME = \"vocab.txt\"\n",
    "\n",
    "with open(VOC_FNAME, \"w\") as fo:\n",
    "  for token in bert_vocab:\n",
    "    fo.write(token+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "ScifdT3eBPUH",
    "outputId": "93b746f4-8683-4892-9f60-e840cce8694d"
   },
   "outputs": [],
   "source": [
    "bert_tokenizer = tokenization.FullTokenizer(VOC_FNAME)\n",
    "bert_tokenizer.tokenize(first_10_rows.Body[0])[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DF5eYR9d0ZuL"
   },
   "source": [
    "## Generating pre-trained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ZixF84ZD0YH7",
    "outputId": "26d46f14-67c5-4919-ee7e-152572802e2f"
   },
   "outputs": [],
   "source": [
    "# sharding the dataset\n",
    "!mkdir ./shards\n",
    "!split -a 4 -l 5560 -d $PRC_DATA_FPATH ./shards/shard_\n",
    "!ls ./shards/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6yedcP1p1JMF"
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 128 #@param {type:\"integer\"}\n",
    "MASKED_LM_PROB = 0.15 #@param\n",
    "MAX_PREDICTIONS = 20 #@param {type:\"integer\"}\n",
    "DO_LOWER_CASE = True #@param {type:\"boolean\"}\n",
    "PROCESSES = 2 #@param {type:\"integer\"}\n",
    "PRETRAINING_DIR = \"pretraining_data\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9b555cSS1c0b"
   },
   "source": [
    "For each shard we need to call `create_pretraining_data.py` script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5x2g476x1TJ-"
   },
   "outputs": [],
   "source": [
    "XARGS_CMD = (\"ls ./shards/ | \"\n",
    "             \"xargs -n 1 -P {} -I{} \"\n",
    "             \"python3 bert/create_pretraining_data.py \"\n",
    "             \"--input_file=./shards/{} \"\n",
    "             \"--output_file={}/{}.tfrecord \"\n",
    "             \"--vocab_file={} \"\n",
    "             \"--do_lower_case={} \"\n",
    "             \"--max_predictions_per_seq={} \"\n",
    "             \"--max_seq_length={} \"\n",
    "             \"--masked_lm_prob={} \"\n",
    "             \"--random_seed=34 \"\n",
    "             \"--dupe_factor=5\")\n",
    "\n",
    "XARGS_CMD = XARGS_CMD.format(PROCESSES, '{}', '{}', PRETRAINING_DIR, '{}', \n",
    "                             VOC_FNAME, DO_LOWER_CASE, \n",
    "                             MAX_PREDICTIONS, MAX_SEQ_LENGTH, MASKED_LM_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eBei5rgb1jn3",
    "outputId": "0a76a538-ed96-4229-e678-259b82df0876"
   },
   "outputs": [],
   "source": [
    "tf.gfile.MkDir(PRETRAINING_DIR)\n",
    "!$XARGS_CMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil -m cp -r gs://ekaba-assets/pre_trained_data ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VptZ5CEx3wWB"
   },
   "source": [
    "# Train the BioMedBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud auth application-default login --no-launch-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user tensorflow==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade \"cloud-tpu-profiler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export PATH=\"$PATH:`python -m site --user-base`/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import tensorflow as tf\n",
    "# import tensorflow.compat.v2 as tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0uz-18dZ2tDH"
   },
   "source": [
    "Save model assets and checkpoints to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LMZKDdyL1pb3"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"ekaba-assets\"\n",
    "MODEL_DIR = \"bert_model_sat_18th_april\"\n",
    "tf.io.gfile.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2mVR9qBK3V5j"
   },
   "source": [
    "Hyparameter configuration for BERT BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOC_SIZE = 32000\n",
    "VOC_FNAME = \"biomedbert-8M.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oIibj7MY3TH5"
   },
   "outputs": [],
   "source": [
    "# use this for BERT-base\n",
    "\n",
    "bert_base_config = {\n",
    "  \"attention_probs_dropout_prob\": 0.1, \n",
    "  \"directionality\": \"bidi\", \n",
    "  \"hidden_act\": \"gelu\", \n",
    "  \"hidden_dropout_prob\": 0.1, \n",
    "  \"hidden_size\": 768, \n",
    "  \"initializer_range\": 0.02, \n",
    "  \"intermediate_size\": 3072, \n",
    "  \"max_position_embeddings\": 512, \n",
    "  \"num_attention_heads\": 12, \n",
    "  \"num_hidden_layers\": 12, \n",
    "  \"pooler_fc_size\": 768, \n",
    "  \"pooler_num_attention_heads\": 12, \n",
    "  \"pooler_num_fc_layers\": 3, \n",
    "  \"pooler_size_per_head\": 128, \n",
    "  \"pooler_type\": \"first_token_transform\", \n",
    "  \"type_vocab_size\": 2, \n",
    "  \"vocab_size\": VOC_SIZE\n",
    "}\n",
    "\n",
    "with open(\"{}/bert_config.json\".format(MODEL_DIR), \"w\") as fo:\n",
    "    json.dump(bert_base_config, fo, indent=2)\n",
    "  \n",
    "# with open(\"{}/{}\".format(MODEL_DIR, VOC_FNAME), \"w\") as fo:\n",
    "#   for token in bert_vocab:\n",
    "#     fo.write(token+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil -m cp -r $MODEL_DIR gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "2QHoAJs63PrO",
    "outputId": "c98a8bcb-9ba0-43d1-9fe7-4df5f80419df"
   },
   "outputs": [],
   "source": [
    "# if BUCKET_NAME:\n",
    "#   !gsutil -m cp -r $MODEL_DIR $PRETRAINING_DIR gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import bert modules\n",
    "sys.path.append(\"bert\")\n",
    "from bert import modeling, optimization, tokenization\n",
    "from bert.run_pretraining import input_fn_builder, model_fn_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QR5ffWV15OHf"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# configure logging\n",
    "log = logging.getLogger('tensorflow')\n",
    "log.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "u0fRU1XT3vu-",
    "outputId": "268c16ab-9274-4d9a-e185-b46b556dfd00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using checkpoint: gs://ekaba-assets/bert_model_sat_18th_april/model.ckpt-1000000\n",
      "INFO:tensorflow:Using 10000 data shards\n"
     ]
    }
   ],
   "source": [
    "# BUCKET_NAME = \"ekaba-assets\" # \"ekaba-assets\" #@param {type:\"string\"}\n",
    "# MODEL_DIR = \"bert_model_sat_18th_april\" #@param {type:\"string\"}\n",
    "PRETRAINING_DIR = \"pre_trained_data\" #@param {type:\"string\"}\n",
    "VOC_FNAME = \"biomedbert-8M.txt\" #@param {type:\"string\"}\n",
    "\n",
    "# Input data pipeline config\n",
    "TRAIN_BATCH_SIZE = 128 #@param {type:\"integer\"}\n",
    "MAX_PREDICTIONS = 20 #@param {type:\"integer\"}\n",
    "MAX_SEQ_LENGTH = 128 #@param {type:\"integer\"}\n",
    "MASKED_LM_PROB = 0.15 #@param\n",
    "\n",
    "# Training procedure config\n",
    "EVAL_BATCH_SIZE = 128#64\n",
    "LEARNING_RATE = 2e-5\n",
    "TRAIN_STEPS = 1000000 #@param {type:\"integer\"}\n",
    "SAVE_CHECKPOINTS_STEPS = 2500 #@param {type:\"integer\"}\n",
    "NUM_TPU_CORES = 128\n",
    "\n",
    "if BUCKET_NAME:\n",
    "    BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n",
    "else:\n",
    "    BUCKET_PATH = \".\"\n",
    "\n",
    "BERT_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, MODEL_DIR)\n",
    "DATA_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, PRETRAINING_DIR)\n",
    "\n",
    "VOCAB_FILE = os.path.join(BERT_GCS_DIR, VOC_FNAME)\n",
    "CONFIG_FILE = os.path.join(BERT_GCS_DIR, \"bert_config.json\")\n",
    "\n",
    "INIT_CHECKPOINT = tf.train.latest_checkpoint(BERT_GCS_DIR)\n",
    "\n",
    "bert_config = modeling.BertConfig.from_json_file(CONFIG_FILE)\n",
    "input_files = tf.io.gfile.glob(os.path.join(DATA_GCS_DIR,'*tfrecord'))\n",
    "\n",
    "log.info(\"Using checkpoint: {}\".format(INIT_CHECKPOINT))\n",
    "log.info(\"Using {} data shards\".format(len(input_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ekaba-assets/bert_model_sat_18th_april/biomedbert-8M.txt\n",
      "gs://ekaba-assets/bert_model_sat_18th_april/bert_config.json\n",
      "gs://ekaba-assets/bert_model_sat_18th_april/model.ckpt-1000000\n"
     ]
    }
   ],
   "source": [
    "print(VOCAB_FILE)\n",
    "print(CONFIG_FILE)\n",
    "print(INIT_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export VOCAB_FILE=gs://ekaba-assets/bert_model_sat_18th_april/biomedbert-8M.txt\n",
    "export CONFIG_FILE=BioMedBERT/notebooks/bert_model_sat_18th_april/bert_config.json\n",
    "export INIT_CHECKPOINT=gs://ekaba-assets/bert_model_sat_18th_april/model.ckpt-1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILE='BioMedBERT/notebooks/bert_model_sat_18th_april/bert_config.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jEawhTlo5frp"
   },
   "source": [
    "**Train on TPUs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "513l2s0g5nOx",
    "outputId": "9ab147b4-2d1f-49a9-aee3-b552de014b80"
   },
   "outputs": [],
   "source": [
    "# if 'TPU_NAME' in os.environ:\n",
    "#     log.info(\"Using TPU runtime\")\n",
    "#     USE_TPU = True\n",
    "#     TPU_ADDRESS = 'grpc://' + '10.250.1.2:8470'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export BERT_GCS_DIR=BERT_GCS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !echo $BERT_GCS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export TPU_NAME=for-ekaba-tpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export STORAGE_BUCKET=gs://ekaba-assets/\n",
    "# !export MODEL_DIR=gs://ekaba-assets/bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !capture_tpu_profile --tpu=${TPU_NAME} --logdir=${BERT_GCS_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "aM4Vn5RZ3pqk",
    "outputId": "b96576de-fb9c-47a2-b770-572e99dba93b"
   },
   "outputs": [],
   "source": [
    "USE_TPU = True\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "      bert_config=bert_config,\n",
    "      init_checkpoint=INIT_CHECKPOINT,\n",
    "      learning_rate=LEARNING_RATE,\n",
    "      num_train_steps=TRAIN_STEPS,\n",
    "      num_warmup_steps=10,\n",
    "      use_tpu=USE_TPU,\n",
    "      use_one_hot_embeddings=True,\n",
    "      log_dir=BERT_GCS_DIR\n",
    ")\n",
    "\n",
    "# tpu_cluster_resolver =  tf.distribute.cluster_resolver.TPUClusterResolver(\n",
    "#     tpu=TPU_ADDRESS, zone='us-central1-a', project='ai-vs-covid19', job_name='biomedbert')\n",
    "\n",
    "tpu_cluster_resolver =  tf.distribute.cluster_resolver.TPUClusterResolver(\n",
    "    zone='europe-west4-a', project='ai-vs-covid19', job_name='biomedbert')\n",
    "\n",
    "run_config = tf.compat.v1.estimator.tpu.RunConfig(\n",
    "    cluster=tpu_cluster_resolver,\n",
    "    model_dir=BERT_GCS_DIR,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
    "    tpu_config=tf.compat.v1.estimator.tpu.TPUConfig(\n",
    "        iterations_per_loop=SAVE_CHECKPOINTS_STEPS,\n",
    "        num_shards=NUM_TPU_CORES,\n",
    "        per_host_input_for_training=tf.compat.v1.estimator.tpu.InputPipelineConfig.PER_HOST_V2))\n",
    "\n",
    "estimator = tf.compat.v1.estimator.tpu.TPUEstimator(\n",
    "    use_tpu=USE_TPU,\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    eval_batch_size=EVAL_BATCH_SIZE)\n",
    "  \n",
    "train_input_fn = input_fn_builder(\n",
    "        input_files=input_files,\n",
    "        max_seq_length=MAX_SEQ_LENGTH,\n",
    "        max_predictions_per_seq=MAX_PREDICTIONS,\n",
    "        is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-3KYolcy5kvn",
    "outputId": "03a57f14-eba6-4e78-9325-63677b8cb253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Skipping training since max_steps has already saved.\n",
      "INFO:tensorflow:training_loop marked as finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.tpu.tpu_estimator.TPUEstimator at 0x7f638b7b5c18>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=train_input_fn, max_steps=TRAIN_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract pre-trained contextual embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !echo 'Who was Jim Henson ? ||| Jim Henson was a puppeteer' > ./input.txt #/tmp/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TXT = 'input_fra.txt'\n",
    "OUTPUT_FILE = 'output_fra.jsonl'\n",
    "processes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "XARGS_CMD = (\"python3 bert/extract_features.py \"\n",
    "             \"--input_file={} \"\n",
    "             \"--output_file={} \"\n",
    "             \"--vocab_file={} \"\n",
    "             \"--bert_config_file={} \"\n",
    "             \"--init_checkpoint={} \"\n",
    "             \"--layers=-1,-2,-3,-4 \"\n",
    "             \"--max_seq_length=128 \"\n",
    "             \"--batch_size=8 \")\n",
    "\n",
    "XARGS_CMD = XARGS_CMD.format(INPUT_TXT, OUTPUT_FILE, VOCAB_FILE,\n",
    "                             CONFIG_FILE, INIT_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!$XARGS_CMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 bert/extract_features.py --input_file='input.txt' --output_file='output.jsonl' --vocab_file=VOCAB_FILE --bert_config_file=bert_config --init_checkpoint=INIT_CHECKPOINT --layers=-1,-2,-3,-4 --max_seq_length=128 --batch_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BioMedBERT-Data-Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
