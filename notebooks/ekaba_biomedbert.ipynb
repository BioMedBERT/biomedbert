{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E08w9hc0TAbI"
   },
   "source": [
    "# BioMedBERT BigQuery Data Analysis/ Pre-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zmQTSz_7Sy30"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "import tensorflow as tf\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I348xIulUEnV"
   },
   "outputs": [],
   "source": [
    "project_id = 'ai-vs-covid19'\n",
    "client = bigquery.Client(project=project_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gL4YG5N6Tn61"
   },
   "source": [
    "## Query Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "HvHzfvtKT6c9",
    "outputId": "c2e55ef1-3886-49b5-e4d0-2be6083d4926"
   },
   "outputs": [],
   "source": [
    "# Get number of rows\n",
    "row_count = client.query('''\n",
    "  SELECT \n",
    "    COUNT(*) as total\n",
    "  FROM `ai-vs-covid19.BigBioMedBERT2.ncbi_comm_use`''').to_dataframe().total\n",
    "row_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "7urYHJj7UZXX",
    "outputId": "08e96a86-7ac0-42ea-97c3-ba93f9684512"
   },
   "outputs": [],
   "source": [
    "# get column names\n",
    "col_names = client.query('''\n",
    "  SELECT column_name\n",
    "  FROM `ai-vs-covid19.BigBioMedBERT2`.INFORMATION_SCHEMA.COLUMNS\n",
    "  WHERE table_name = 'ncbi_comm_use'\n",
    "''').to_dataframe()\n",
    "col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "8nEHxJIhVUOl",
    "outputId": "4408561d-0ef4-4305-c4e1-181205b32193"
   },
   "outputs": [],
   "source": [
    "# get general table information schema\n",
    "table_schema = client.query('''\n",
    "  SELECT *\n",
    "  FROM `ai-vs-covid19.BigBioMedBERT2`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS\n",
    "  WHERE table_name = 'ncbi_comm_use'\n",
    "''').to_dataframe()\n",
    "table_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "colab_type": "code",
    "id": "eDhjuF80V8pl",
    "outputId": "a223c11e-1201-403b-820f-4fd1adaa5f15"
   },
   "outputs": [],
   "source": [
    "# select first 10 rows\n",
    "first_10_rows = client.query('''\n",
    "  SELECT *\n",
    "  FROM `ai-vs-covid19.BigBioMedBERT2.ncbi_comm_use`\n",
    "  LIMIT 10\n",
    "''').to_dataframe()\n",
    "first_10_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YtA3hlOcWpsW"
   },
   "outputs": [],
   "source": [
    "# print body text\n",
    "def print_body(body_series: pd.Series) -> str:\n",
    "  print(textwrap.fill(body_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "colab_type": "code",
    "id": "0up3UTnLW1kA",
    "outputId": "1d7af912-bc5b-4af1-90fd-088254208795"
   },
   "outputs": [],
   "source": [
    "print_body(first_10_rows.Body[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i6qIv0aCfioQ"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "zo9iWkzrfzM9",
    "outputId": "d21cbd0c-aecc-4e4c-8c54-f6c2dc6122c9"
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece\n",
    "# !git clone https://github.com/google-research/bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_k54abHhhGP3"
   },
   "outputs": [],
   "source": [
    "# base imports\n",
    "import os\n",
    "import sys\n",
    "import nltk\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "XOj-PvpHd0SC",
    "outputId": "bc809857-8cde-4017-aec4-926b446848aa"
   },
   "outputs": [],
   "source": [
    "#import bert modules\n",
    "sys.path.append(\"bert\")\n",
    "from bert import modeling, optimization, tokenization\n",
    "from bert.run_pretraining import input_fn_builder, model_fn_builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0Vw0rZIhsqI"
   },
   "source": [
    "### Preprocess text\n",
    "Remove punсtuation, uppercase letters and non-utf symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QLnaz54Pg13C"
   },
   "outputs": [],
   "source": [
    "regex_tokenizer = nltk.RegexpTokenizer(\"\\w+\")\n",
    "\n",
    "def normalize_text(text):\n",
    "  # lowercase text\n",
    "  text = str(text).lower()\n",
    "  # remove non-UTF\n",
    "  text = text.encode(\"utf-8\", \"ignore\").decode()\n",
    "  # remove punctuation symbols\n",
    "  text = \" \".join(regex_tokenizer.tokenize(text))\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vJ9M2-aYiAXb",
    "outputId": "b462ab03-011e-44ff-e743-0a62c58729fa"
   },
   "outputs": [],
   "source": [
    "# example to normalize text from ``Body`` in BioMedBERT dataset\n",
    "print_body(normalize_text(first_10_rows.Body[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fk8rgWTLGoXT"
   },
   "source": [
    "## Create Expanded csv dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LOiLn33dPPbl"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IbunQH1_SWWc"
   },
   "outputs": [],
   "source": [
    "storage_client = storage.Client(project=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1tpbvp2ASAjC"
   },
   "outputs": [],
   "source": [
    "bucket=storage_client.get_bucket('big_bio_med_bert_dump_csv')\n",
    "# List all objects that satisfy the filter.\n",
    "blobs=bucket.list_blobs(prefix='ncbi_comm_use')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8pAaD8geSAmS"
   },
   "outputs": [],
   "source": [
    "blob = [blob for blob in blobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "WHy-ysLfnozM",
    "outputId": "aff1f76f-db54-4112-82ae-869c601603c7"
   },
   "outputs": [],
   "source": [
    "print(len(blob))\n",
    "print(len(blob) // 5)\n",
    "print((len(blob) // 5)*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f9pcw0ZhTas1"
   },
   "outputs": [],
   "source": [
    "# Create a function called \"chunks\" with two arguments, l and n:\n",
    "def split_list(data, chunk):\n",
    "    # For item i in a range that is a length of data (l),\n",
    "    for i in range(0, len(data), chunk):\n",
    "        # Create an index range for data of chunk (e.g. 5) items:\n",
    "        yield data[i:i+chunk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oi-tMaehoGZf"
   },
   "outputs": [],
   "source": [
    "# list of length in which we have to split \n",
    "blob_split_1, blob_split_2, blob_split_3, blob_split_4, blob_split_5 = list(split_list(blob, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "NMr8VEj8TbG9",
    "outputId": "ba4d3303-a2ad-4552-bae6-5dbc628d6ada"
   },
   "outputs": [],
   "source": [
    "print(len(blob))\n",
    "print(len(blob_split_1))\n",
    "print(len(blob_split_2))\n",
    "print(len(blob_split_3))\n",
    "print(len(blob_split_4))\n",
    "print(len(blob_split_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "-MakXh7v31xU",
    "outputId": "631dac94-aad5-4927-860b-765a3dc29695"
   },
   "outputs": [],
   "source": [
    "blob_split_1[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "7eqOehVw4Lhh",
    "outputId": "2efffffb-8d4f-40a7-db40-a6a300770e51"
   },
   "outputs": [],
   "source": [
    "blob_split_2[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8-dXTAMgTur6"
   },
   "outputs": [],
   "source": [
    "def download_to_local(folder, blob_lst):\n",
    "    print('File download Started…. Wait for the job to complete.')\n",
    "    # Create this folder locally if not exists\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    # Iterating through for loop one by one using API call\n",
    "    for blob in blob_lst:\n",
    "#         print('Blobs: {}'.format(blob.name))\n",
    "        destination_uri = '{}/{}'.format(folder, (blob.name).split('/')[-1])\n",
    "        blob.download_to_filename(destination_uri)\n",
    "        print('Exported {} to {}'.format(blob.name, destination_uri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g-CWG7n41_5x"
   },
   "outputs": [],
   "source": [
    "# !rm -rf data #data_1 data_2 data_3 data_4 #data_5\n",
    "# !rm ncbi_comm_use_csv_A.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "S-luesxCT4uT",
    "outputId": "9ab6d42e-49c5-4fd2-abcf-38fd510e3ea3"
   },
   "outputs": [],
   "source": [
    "# download first part of csv's\n",
    "# download_to_local('data', blob)\n",
    "# download_to_local('data_1', blob_split_1)\n",
    "# download_to_local('data_2', blob_split_2)\n",
    "# download_to_local('data_3', blob_split_3)\n",
    "# download_to_local('data_4', blob_split_4)\n",
    "# download_to_local('data_5', blob_split_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96PJ6YMXT4xY"
   },
   "outputs": [],
   "source": [
    "# make combined csv\n",
    "def combined_csv(data_folder):\n",
    "    extension = 'csv'\n",
    "    all_filenames = [i for i in glob.glob('{}/*.{}'.format(data_folder, extension))]\n",
    "    #combine all files in the list\n",
    "    combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "    return combined_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zdBDgQhnUrsp"
   },
   "outputs": [],
   "source": [
    "# blob_csv_A = combined_csv('data')\n",
    "# blob_csv = combined_csv('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dBVxTfO2Urqm",
    "outputId": "92f57f11-69db-493d-b367-099115c2ee0b"
   },
   "outputs": [],
   "source": [
    "# len(blob_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FX9RsVjKbc_Z"
   },
   "outputs": [],
   "source": [
    "# blob_csv.to_csv('gs://ekaba-assets/ncbi_comm_use.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9udoWp5weDq0"
   },
   "outputs": [],
   "source": [
    "# blob_csv_A.to_csv( \"ncbi_comm_use_csv_A.csv\", index=False, encoding='utf-8-sig')\n",
    "# blob_csv.to_csv( \"ncbi_comm_use.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OsbTPI7aGmQs"
   },
   "outputs": [],
   "source": [
    "# copy files from gcs bucket\n",
    "# !gsutil -m cp gs://ekaba-assets/ncbi_comm_use_BODY.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ad8s14h8QL4d"
   },
   "outputs": [],
   "source": [
    "# body = pd.read_csv('ncbi_comm_use.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body_sel = body[['Body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body_sel.to_csv('gs://ekaba-assets/ncbi_comm_use_BODY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body_sel.to_csv( \"ncbi_comm_use_BODY.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove FULL ncbi_comm_use.csv\n",
    "# !rm ncbi_comm_use.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nRTgOh2UQL0M"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YOWtq2VJq2m7"
   },
   "outputs": [],
   "source": [
    "# convert csv to txt\n",
    "import csv\n",
    "import sys\n",
    "maxInt = sys.maxsize\n",
    "csv.field_size_limit(maxInt)\n",
    "\n",
    "csv_file = 'ncbi_comm_use_BODY.csv'\n",
    "txt_file = 'ncbi_comm_use_BODY.txt'\n",
    "with open(txt_file, \"w\") as my_output_file:\n",
    "    with open(csv_file, \"r\") as my_input_file:\n",
    "        [ my_output_file.write(\" \".join(row)+'\\n') for row in csv.reader(my_input_file)]\n",
    "    my_output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move text file to GCS\n",
    "# !gsutil -m cp ncbi_comm_use_BODY.txt gs://ekaba-assets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove csv file\n",
    "# !rm ncbi_comm_use_BODY.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8xAPAIXtspSk"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Progbar\n",
    "def count_lines(filename):\n",
    "  count = 0\n",
    "  with open(filename) as fi:\n",
    "    for line in fi:\n",
    "      count += 1\n",
    "  return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lnyso68uBp8r",
    "outputId": "a23ada36-710c-4099-b07b-145e7e03aa19"
   },
   "outputs": [],
   "source": [
    "# Apply normalization to entire dataset\n",
    "RAW_DATA_FPATH = \"ncbi_comm_use_BODY.txt\"\n",
    "PRC_DATA_FPATH = \"processed_ncbi_comm_use_BODY.txt\"\n",
    "\n",
    "# apply normalization to the dataset\n",
    "\n",
    "total_lines = count_lines(RAW_DATA_FPATH)\n",
    "bar = Progbar(total_lines)\n",
    "\n",
    "with open(RAW_DATA_FPATH,encoding=\"utf-8\") as fi:\n",
    "  with open(PRC_DATA_FPATH, \"w\",encoding=\"utf-8\") as fo:\n",
    "    for l in fi:\n",
    "      fo.write(normalize_text(l)+\"\\n\")\n",
    "      bar.add(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move processed text file to GCS\n",
    "# !gsutil -m cp processed_ncbi_comm_use_BODY.txt gs://ekaba-assets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove intermediate files\n",
    "# !rm ncbi_comm_use_BODY.csv ncbi_comm_use_BODY.txt #processed_ncbi_comm_use_BODY.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3QSqf2hLpk6d"
   },
   "source": [
    "## Building the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRC_DATA_FPATH = \"processed_ncbi_comm_use_BODY.txt\"\n",
    "MODEL_PREFIX = \"biomedbert\" #@param {type: \"string\"}\n",
    "VOC_SIZE = 32000 #@param {type:\"integer\"}\n",
    "SUBSAMPLE_SIZE = 12800000 #@param {type:\"integer\"}\n",
    "NUM_PLACEHOLDERS = 256 #@param {type:\"integer\"}\n",
    "\n",
    "SPM_COMMAND = ('--input={} --model_prefix={} '\n",
    "               '--vocab_size={} --input_sentence_size={} '\n",
    "               '--shuffle_input_sentence=true ' \n",
    "               '--bos_id=-1 --eos_id=-1').format(\n",
    "               PRC_DATA_FPATH, MODEL_PREFIX, \n",
    "               VOC_SIZE - NUM_PLACEHOLDERS, SUBSAMPLE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TUgPWa78sDjx",
    "outputId": "946a4f79-56d7-4182-896a-214bd95fa0e0"
   },
   "outputs": [],
   "source": [
    "spm.SentencePieceTrainer.Train(SPM_COMMAND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "0zMTm7QJsdvQ",
    "outputId": "2e5ba2d6-1e11-4733-98e1-abc64d942953"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "91Vla2Ivx2S4",
    "outputId": "f0c7ee08-7b06-4f41-ff5d-9249ed0294ca"
   },
   "outputs": [],
   "source": [
    "!head -n 30 tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2skaOTxux5Xq"
   },
   "outputs": [],
   "source": [
    "def read_sentencepiece_vocab(filepath):\n",
    "  voc = []\n",
    "  with open(filepath, encoding='utf-8') as fi:\n",
    "    for line in fi:\n",
    "      voc.append(line.split(\"\\t\")[0])\n",
    "  # skip the first <unk> token\n",
    "  voc = voc[1:]\n",
    "  return voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "2u0i7LeJAmnO",
    "outputId": "3195d499-ff7a-4453-c41d-1bc51f685c0b"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "snt_vocab = read_sentencepiece_vocab(\"{}.vocab\".format(MODEL_PREFIX))\n",
    "print(\"Learnt vocab size: {}\".format(len(snt_vocab)))\n",
    "print(\"Sample tokens: {}\".format(random.sample(snt_vocab, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mCW9uiQMAw1G"
   },
   "outputs": [],
   "source": [
    "def parse_sentencepiece_token(token):\n",
    "    if token.startswith(\"▁\"):\n",
    "        return token[1:]\n",
    "    else:\n",
    "        return \"##\" + token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cq3ArCOvA4kV"
   },
   "outputs": [],
   "source": [
    "bert_vocab = list(map(parse_sentencepiece_token, snt_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hy-jY1pQA7aO"
   },
   "outputs": [],
   "source": [
    "ctrl_symbols = [\"[PAD]\",\"[UNK]\",\"[CLS]\",\"[SEP]\",\"[MASK]\"]\n",
    "bert_vocab = ctrl_symbols + bert_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gdq1IFoGBEAq",
    "outputId": "984065a5-f5f1-4afe-8102-0983161bc16f"
   },
   "outputs": [],
   "source": [
    "bert_vocab += [\"[UNUSED_{}]\".format(i) for i in range(VOC_SIZE - len(bert_vocab))]\n",
    "print(len(bert_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQHKGBCYBF5_"
   },
   "outputs": [],
   "source": [
    "# write vocabulary to file\n",
    "VOC_FNAME = \"vocab.txt\"\n",
    "\n",
    "with open(VOC_FNAME, \"w\") as fo:\n",
    "  for token in bert_vocab:\n",
    "    fo.write(token+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "ScifdT3eBPUH",
    "outputId": "93b746f4-8683-4892-9f60-e840cce8694d"
   },
   "outputs": [],
   "source": [
    "bert_tokenizer = tokenization.FullTokenizer(VOC_FNAME)\n",
    "bert_tokenizer.tokenize(first_10_rows.Body[0])[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DF5eYR9d0ZuL"
   },
   "source": [
    "## Generating pre-trained data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ZixF84ZD0YH7",
    "outputId": "26d46f14-67c5-4919-ee7e-152572802e2f"
   },
   "outputs": [],
   "source": [
    "# sharding the dataset\n",
    "!mkdir ./shards\n",
    "!split -a 4 -l 5560 -d $PRC_DATA_FPATH ./shards/shard_\n",
    "!ls ./shards/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6yedcP1p1JMF"
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 128 #@param {type:\"integer\"}\n",
    "MASKED_LM_PROB = 0.15 #@param\n",
    "MAX_PREDICTIONS = 20 #@param {type:\"integer\"}\n",
    "DO_LOWER_CASE = True #@param {type:\"boolean\"}\n",
    "PROCESSES = 2 #@param {type:\"integer\"}\n",
    "PRETRAINING_DIR = \"pretraining_data\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9b555cSS1c0b"
   },
   "source": [
    "For each shard we need to call `create_pretraining_data.py` script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5x2g476x1TJ-"
   },
   "outputs": [],
   "source": [
    "XARGS_CMD = (\"ls ./shards/ | \"\n",
    "             \"xargs -n 1 -P {} -I{} \"\n",
    "             \"python3 bert/create_pretraining_data.py \"\n",
    "             \"--input_file=./shards/{} \"\n",
    "             \"--output_file={}/{}.tfrecord \"\n",
    "             \"--vocab_file={} \"\n",
    "             \"--do_lower_case={} \"\n",
    "             \"--max_predictions_per_seq={} \"\n",
    "             \"--max_seq_length={} \"\n",
    "             \"--masked_lm_prob={} \"\n",
    "             \"--random_seed=34 \"\n",
    "             \"--dupe_factor=5\")\n",
    "\n",
    "XARGS_CMD = XARGS_CMD.format(PROCESSES, '{}', '{}', PRETRAINING_DIR, '{}', \n",
    "                             VOC_FNAME, DO_LOWER_CASE, \n",
    "                             MAX_PREDICTIONS, MAX_SEQ_LENGTH, MASKED_LM_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eBei5rgb1jn3",
    "outputId": "0a76a538-ed96-4229-e678-259b82df0876"
   },
   "outputs": [],
   "source": [
    "tf.gfile.MkDir(PRETRAINING_DIR)\n",
    "!$XARGS_CMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil -m cp -r gs://ekaba-assets/pre_trained_data ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VptZ5CEx3wWB"
   },
   "source": [
    "# Train the BioMedBERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud auth application-default login --no-launch-browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --user tensorflow==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade \"cloud-tpu-profiler\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export PATH=\"$PATH:`python -m site --user-base`/bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import tensorflow as tf\n",
    "# import tensorflow.compat.v2 as tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0uz-18dZ2tDH"
   },
   "source": [
    "Save model assets and checkpoints to GCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LMZKDdyL1pb3"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"ekaba-assets\"\n",
    "MODEL_DIR = \"bert_model_10M\"\n",
    "tf.io.gfile.mkdir(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2mVR9qBK3V5j"
   },
   "source": [
    "Hyparameter configuration for BERT BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOC_SIZE = 32000\n",
    "VOC_FNAME = \"biomedbert-8M.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oIibj7MY3TH5"
   },
   "outputs": [],
   "source": [
    "# use this for BERT-base\n",
    "\n",
    "bert_base_config = {\n",
    "  \"attention_probs_dropout_prob\": 0.1, \n",
    "  \"directionality\": \"bidi\", \n",
    "  \"hidden_act\": \"gelu\", \n",
    "  \"hidden_dropout_prob\": 0.1, \n",
    "  \"hidden_size\": 768, \n",
    "  \"initializer_range\": 0.02, \n",
    "  \"intermediate_size\": 3072, \n",
    "  \"max_position_embeddings\": 512, \n",
    "  \"num_attention_heads\": 12, \n",
    "  \"num_hidden_layers\": 12, \n",
    "  \"pooler_fc_size\": 768, \n",
    "  \"pooler_num_attention_heads\": 12, \n",
    "  \"pooler_num_fc_layers\": 3, \n",
    "  \"pooler_size_per_head\": 128, \n",
    "  \"pooler_type\": \"first_token_transform\", \n",
    "  \"type_vocab_size\": 2, \n",
    "  \"vocab_size\": VOC_SIZE\n",
    "}\n",
    "\n",
    "with open(\"{}/bert_config.json\".format(MODEL_DIR), \"w\") as fo:\n",
    "    json.dump(bert_base_config, fo, indent=2)\n",
    "  \n",
    "# with open(\"{}/{}\".format(MODEL_DIR, VOC_FNAME), \"w\") as fo:\n",
    "#   for token in bert_vocab:\n",
    "#     fo.write(token+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gsutil -m cp -r $MODEL_DIR gs://$BUCKET_NAME,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "2QHoAJs63PrO",
    "outputId": "c98a8bcb-9ba0-43d1-9fe7-4df5f80419df"
   },
   "outputs": [],
   "source": [
    "# if BUCKET_NAME:\n",
    "#   !gsutil -m cp -r $MODEL_DIR $PRETRAINING_DIR gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import bert modules\n",
    "sys.path.append(\"bert\")\n",
    "from bert import modeling, optimization, tokenization\n",
    "from bert.run_pretraining import input_fn_builder, model_fn_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QR5ffWV15OHf"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# configure logging\n",
    "log = logging.getLogger('tensorflow')\n",
    "log.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "u0fRU1XT3vu-",
    "outputId": "268c16ab-9274-4d9a-e185-b46b556dfd00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using checkpoint: gs://ekaba-assets/bert_model_10M/model.ckpt-3827500\n",
      "INFO:tensorflow:Using 10000 data shards\n"
     ]
    }
   ],
   "source": [
    "# BUCKET_NAME = \"ekaba-assets\" # \"ekaba-assets\" #@param {type:\"string\"}\n",
    "# MODEL_DIR = \"bert_model_sat_18th_april\" #@param {type:\"string\"}\n",
    "PRETRAINING_DIR = \"pre_trained_data\" #@param {type:\"string\"}\n",
    "VOC_FNAME = \"biomedbert-8M.txt\" #@param {type:\"string\"}\n",
    "\n",
    "# Input data pipeline config\n",
    "TRAIN_BATCH_SIZE = 128 #@param {type:\"integer\"}\n",
    "MAX_PREDICTIONS = 20 #@param {type:\"integer\"}\n",
    "MAX_SEQ_LENGTH = 128 #@param {type:\"integer\"}\n",
    "MASKED_LM_PROB = 0.15 #@param\n",
    "\n",
    "# Training procedure config\n",
    "EVAL_BATCH_SIZE = 128 #64\n",
    "LEARNING_RATE = 1e-5  #2e-5\n",
    "TRAIN_STEPS = 10000000 #@param {type:\"integer\"}\n",
    "SAVE_CHECKPOINTS_STEPS = 2500 #@param {type:\"integer\"}\n",
    "NUM_TPU_CORES = 128\n",
    "\n",
    "if BUCKET_NAME:\n",
    "    BUCKET_PATH = \"gs://{}\".format(BUCKET_NAME)\n",
    "else:\n",
    "    BUCKET_PATH = \".\"\n",
    "\n",
    "BERT_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, MODEL_DIR)\n",
    "DATA_GCS_DIR = \"{}/{}\".format(BUCKET_PATH, PRETRAINING_DIR)\n",
    "\n",
    "VOCAB_FILE = os.path.join(BERT_GCS_DIR, VOC_FNAME)\n",
    "CONFIG_FILE = os.path.join(BERT_GCS_DIR, \"bert_config.json\")\n",
    "\n",
    "INIT_CHECKPOINT = tf.train.latest_checkpoint(BERT_GCS_DIR)\n",
    "\n",
    "bert_config = modeling.BertConfig.from_json_file(CONFIG_FILE)\n",
    "input_files = tf.io.gfile.glob(os.path.join(DATA_GCS_DIR,'*tfrecord'))\n",
    "\n",
    "log.info(\"Using checkpoint: {}\".format(INIT_CHECKPOINT))\n",
    "log.info(\"Using {} data shards\".format(len(input_files)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://ekaba-assets/bert_model_10M/biomedbert-8M.txt\n",
      "gs://ekaba-assets/bert_model_10M/bert_config.json\n",
      "gs://ekaba-assets/bert_model_10M\n",
      "gs://ekaba-assets/bert_model_10M/model.ckpt-3827500\n"
     ]
    }
   ],
   "source": [
    "print(VOCAB_FILE)\n",
    "print(CONFIG_FILE)\n",
    "print(BERT_GCS_DIR)\n",
    "print(INIT_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export VOCAB_FILE=gs://ekaba-assets/bert_model_sat_18th_april/biomedbert-8M.txt\n",
    "# export CONFIG_FILE=gs://ekaba-assets/bert_model_sat_18th_april/bert_config.json\n",
    "# export INIT_CHECKPOINT=gs://ekaba-assets/bert_model_sat_18th_april/model.ckpt-1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG_FILE='BioMedBERT/notebooks/bert_model_sat_18th_april/bert_config.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jEawhTlo5frp"
   },
   "source": [
    "**Train on TPUs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "513l2s0g5nOx",
    "outputId": "9ab147b4-2d1f-49a9-aee3-b552de014b80"
   },
   "outputs": [],
   "source": [
    "# if 'TPU_NAME' in os.environ:\n",
    "#     log.info(\"Using TPU runtime\")\n",
    "#     USE_TPU = True\n",
    "#     TPU_ADDRESS = 'grpc://' + '10.250.1.2:8470'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export BERT_GCS_DIR=BERT_GCS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !echo $BERT_GCS_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for-shweta-tpu\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export TPU_NAME='for-shweta-tpu'\n",
    "echo $TPU_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !export STORAGE_BUCKET=gs://ekaba-assets/\n",
    "# !export MODEL_DIR=gs://ekaba-assets/bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !capture_tpu_profile --tpu=${TPU_NAME} --logdir=${BERT_GCS_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "aM4Vn5RZ3pqk",
    "outputId": "b96576de-fb9c-47a2-b770-572e99dba93b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7fcfd8c1ce18>) includes params argument, but params are not passed to Estimator.\n",
      "INFO:tensorflow:Using config: {'_protocol': None, '_master': 'grpc://10.250.1.7:8470', '_keep_checkpoint_every_n_hours': 10000, '_num_worker_replicas': 1, '_evaluation_master': 'grpc://10.250.1.7:8470', '_is_chief': True, '_tpu_config': TPUConfig(iterations_per_loop=2500, num_shards=128, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2, experimental_host_call_every_n_steps=1), '_device_fn': None, '_train_distribute': None, '_tf_random_seed': None, '_experimental_distribute': None, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7fcfd8b26c18>, '_save_summary_steps': 100, '_session_config': allow_soft_placement: true\n",
      "cluster_def {\n",
      "  job {\n",
      "    name: \"biomedbert\"\n",
      "    tasks {\n",
      "      key: 0\n",
      "      value: \"10.250.1.7:8470\"\n",
      "    }\n",
      "    tasks {\n",
      "      key: 1\n",
      "      value: \"10.250.1.4:8470\"\n",
      "    }\n",
      "    tasks {\n",
      "      key: 2\n",
      "      value: \"10.250.1.2:8470\"\n",
      "    }\n",
      "    tasks {\n",
      "      key: 3\n",
      "      value: \"10.250.1.16:8470\"\n",
      "    }\n",
      "    tasks {\n",
      "      key: 4\n",
      "      value: \"10.250.1.13:8470\"\n",
      "    }\n",
      "    tasks {\n",
      "      key: 5\n",
      "      value: \"10.250.1.15:8470\"\n",
      "    }\n",
      "    tasks {\n",
      "      key: 6\n",
      "      value: \"10.250.1.14:8470\"\n",
      "    }\n",
      "    tasks {\n",
      "      key: 7\n",
      "      value: \"10.250.1.12:8470\"\n",
      "    }\n",
      "    tasks {\n",
      "      key: 8\n",
      "      value: \"10.250.1.8:8470\"\n",
      "    }\n",
      "    tasks {\n",
      "      key: 9\n",
      "      value: \"10.250.1.10:8470\"\n",
      "    }\n",
      "    tasks {\n",
      "      key: 10\n",
      "      value: \"10.250.1.5:8470\"\n",
      "    }\n",
      "    tasks {\n",
      "      key: 11\n",
      "      value: \"10.250.1.3:8470\"\n",
      "    }\n",
      "    tasks {\n",
      "      key: 12\n",
      "      value: \"10.250.1.6:8470\"\n",
      "    }\n",
      "    tasks {\n",
      "      key: 13\n",
      "      value: \"10.250.1.17:8470\"\n",
      "    }\n",
      "    tasks {\n",
      "      key: 14\n",
      "      value: \"10.250.1.11:8470\"\n",
      "    }\n",
      "    tasks {\n",
      "      key: 15\n",
      "      value: \"10.250.1.9:8470\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "isolate_session_state: true\n",
      ", '_session_creation_timeout_secs': 7200, '_task_type': 'worker', '_save_checkpoints_secs': None, '_task_id': 0, '_global_id_in_cluster': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcfd8b44278>, '_save_checkpoints_steps': 2500, '_model_dir': 'gs://ekaba-assets/bert_model_10M', '_eval_distribute': None, '_log_step_count_steps': None}\n",
      "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
     ]
    }
   ],
   "source": [
    "USE_TPU = True\n",
    "\n",
    "model_fn = model_fn_builder(\n",
    "      bert_config=bert_config,\n",
    "      init_checkpoint=INIT_CHECKPOINT,\n",
    "      learning_rate=LEARNING_RATE,\n",
    "      num_train_steps=TRAIN_STEPS,\n",
    "      num_warmup_steps=10,\n",
    "      use_tpu=USE_TPU,\n",
    "      use_one_hot_embeddings=True,\n",
    "      log_dir=BERT_GCS_DIR\n",
    ")\n",
    "\n",
    "# tpu_cluster_resolver =  tf.distribute.cluster_resolver.TPUClusterResolver(\n",
    "#     tpu=TPU_ADDRESS, zone='us-central1-a', project='ai-vs-covid19', job_name='biomedbert')\n",
    "\n",
    "tpu_cluster_resolver =  tf.distribute.cluster_resolver.TPUClusterResolver(\n",
    "    zone='europe-west4-a', project='ai-vs-covid19', job_name='biomedbert', tpu='for-shweta-tpu')\n",
    "\n",
    "run_config = tf.compat.v1.estimator.tpu.RunConfig(\n",
    "    cluster=tpu_cluster_resolver,\n",
    "    model_dir=BERT_GCS_DIR,\n",
    "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
    "    tpu_config=tf.compat.v1.estimator.tpu.TPUConfig(\n",
    "        iterations_per_loop=SAVE_CHECKPOINTS_STEPS,\n",
    "        num_shards=NUM_TPU_CORES,\n",
    "        per_host_input_for_training=tf.compat.v1.estimator.tpu.InputPipelineConfig.PER_HOST_V2))\n",
    "\n",
    "estimator = tf.compat.v1.estimator.tpu.TPUEstimator(\n",
    "    use_tpu=USE_TPU,\n",
    "    model_fn=model_fn,\n",
    "    config=run_config,\n",
    "    train_batch_size=TRAIN_BATCH_SIZE,\n",
    "    eval_batch_size=EVAL_BATCH_SIZE)\n",
    "  \n",
    "train_input_fn = input_fn_builder(\n",
    "        input_files=input_files,\n",
    "        max_seq_length=MAX_SEQ_LENGTH,\n",
    "        max_predictions_per_seq=MAX_PREDICTIONS,\n",
    "        is_training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "-3KYolcy5kvn",
    "outputId": "03a57f14-eba6-4e78-9325-63677b8cb253"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Querying Tensorflow master (grpc://10.250.1.7:8470) for TPU system metadata.\n",
      "INFO:tensorflow:Found TPU system:\n",
      "INFO:tensorflow:*** Num TPU Cores: 128\n",
      "INFO:tensorflow:*** Num TPU Workers: 16\n",
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:0/device:CPU:0, CPU, -1, 11109503997903880436)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:0/device:TPU:0, TPU, 17179869184, 9493420418296365698)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:0/device:TPU:1, TPU, 17179869184, 3912176050004614333)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:0/device:TPU:2, TPU, 17179869184, 18424397470990803709)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:0/device:TPU:3, TPU, 17179869184, 15375562771200582323)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:0/device:TPU:4, TPU, 17179869184, 4259869140682736162)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:0/device:TPU:5, TPU, 17179869184, 7452587145781651834)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:0/device:TPU:6, TPU, 17179869184, 11101725352152644012)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:0/device:TPU:7, TPU, 17179869184, 3881809411163664530)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 10884533713655811126)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 807996899738292970)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:1/device:CPU:0, CPU, -1, 868582349478203692)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:1/device:TPU:0, TPU, 17179869184, 5953294281152380046)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:1/device:TPU:1, TPU, 17179869184, 8312066985935987941)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:1/device:TPU:2, TPU, 17179869184, 10810217556962127544)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:1/device:TPU:3, TPU, 17179869184, 13618852510890378947)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:1/device:TPU:4, TPU, 17179869184, 7512042172586053847)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:1/device:TPU:5, TPU, 17179869184, 10625531516047807919)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:1/device:TPU:6, TPU, 17179869184, 1209452842698824728)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:1/device:TPU:7, TPU, 17179869184, 10947753582281277831)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:1/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 2254994095592772132)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:1/device:XLA_CPU:0, XLA_CPU, 17179869184, 4631472369646580307)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:2/device:CPU:0, CPU, -1, 14959646515135587732)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:2/device:TPU:0, TPU, 17179869184, 3202491940567339391)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:2/device:TPU:1, TPU, 17179869184, 15403316288053791360)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:2/device:TPU:2, TPU, 17179869184, 8925826927049708326)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:2/device:TPU:3, TPU, 17179869184, 16916692798382540711)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:2/device:TPU:4, TPU, 17179869184, 16345540097492469224)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:2/device:TPU:5, TPU, 17179869184, 14200794091323078993)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:2/device:TPU:6, TPU, 17179869184, 15589956814107262076)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:2/device:TPU:7, TPU, 17179869184, 1249577771486296148)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:2/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 12036158655102052531)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:2/device:XLA_CPU:0, XLA_CPU, 17179869184, 10278755709446360038)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:3/device:CPU:0, CPU, -1, 4096060028430713210)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:3/device:TPU:0, TPU, 17179869184, 4834286887066198177)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:3/device:TPU:1, TPU, 17179869184, 16739938223061777208)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:3/device:TPU:2, TPU, 17179869184, 14028702391535604460)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:3/device:TPU:3, TPU, 17179869184, 2178623541351804432)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:3/device:TPU:4, TPU, 17179869184, 12859197318958929421)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:3/device:TPU:5, TPU, 17179869184, 9797002535849726719)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:3/device:TPU:6, TPU, 17179869184, 2892210424712677300)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:3/device:TPU:7, TPU, 17179869184, 17235314538096093909)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:3/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 5404265423836887451)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:3/device:XLA_CPU:0, XLA_CPU, 17179869184, 13996591538342582544)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:4/device:CPU:0, CPU, -1, 6946307083163518396)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:4/device:TPU:0, TPU, 17179869184, 17396332487428736021)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:4/device:TPU:1, TPU, 17179869184, 14318673523398934382)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:4/device:TPU:2, TPU, 17179869184, 474046522897734794)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:4/device:TPU:3, TPU, 17179869184, 3665467525307583506)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:4/device:TPU:4, TPU, 17179869184, 8703011541409082384)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:4/device:TPU:5, TPU, 17179869184, 14603639621965451247)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:4/device:TPU:6, TPU, 17179869184, 6926312690653573658)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:4/device:TPU:7, TPU, 17179869184, 4599541281267590299)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:4/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 5703814982049171147)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:4/device:XLA_CPU:0, XLA_CPU, 17179869184, 13255903042650095735)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:5/device:CPU:0, CPU, -1, 1395676988532386365)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:5/device:TPU:0, TPU, 17179869184, 1802524801111539887)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:5/device:TPU:1, TPU, 17179869184, 12034950977351193023)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:5/device:TPU:2, TPU, 17179869184, 11238360148094230575)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:5/device:TPU:3, TPU, 17179869184, 12677125004215356364)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:5/device:TPU:4, TPU, 17179869184, 17612480778455664565)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:5/device:TPU:5, TPU, 17179869184, 17537166928872777740)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:5/device:TPU:6, TPU, 17179869184, 7110904293979297705)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:5/device:TPU:7, TPU, 17179869184, 175257140258623672)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:5/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 14046268402252847310)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:5/device:XLA_CPU:0, XLA_CPU, 17179869184, 14394968875682776341)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:6/device:CPU:0, CPU, -1, 12576664465371582608)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:6/device:TPU:0, TPU, 17179869184, 8580822795757267823)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:6/device:TPU:1, TPU, 17179869184, 6524240266148317254)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:6/device:TPU:2, TPU, 17179869184, 6417883842520769096)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:6/device:TPU:3, TPU, 17179869184, 1121974795166550963)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:6/device:TPU:4, TPU, 17179869184, 10461224831466554683)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:6/device:TPU:5, TPU, 17179869184, 6004985071563225342)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:6/device:TPU:6, TPU, 17179869184, 18098762164091057051)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:6/device:TPU:7, TPU, 17179869184, 4327272913275072411)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:6/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 14973699361119121532)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:6/device:XLA_CPU:0, XLA_CPU, 17179869184, 2198564736746358225)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:7/device:CPU:0, CPU, -1, 17165064940782342181)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:7/device:TPU:0, TPU, 17179869184, 10874037638953868055)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:7/device:TPU:1, TPU, 17179869184, 15923398195880977129)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:7/device:TPU:2, TPU, 17179869184, 10334274424476905678)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:7/device:TPU:3, TPU, 17179869184, 15811497579130454496)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:7/device:TPU:4, TPU, 17179869184, 7662268513108436301)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:7/device:TPU:5, TPU, 17179869184, 15890361777581742851)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:7/device:TPU:6, TPU, 17179869184, 1938977787297387056)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:7/device:TPU:7, TPU, 17179869184, 10023191286270256362)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:7/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 7715444450450593539)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:7/device:XLA_CPU:0, XLA_CPU, 17179869184, 8183752072220104354)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:8/device:CPU:0, CPU, -1, 3735557161497406303)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:8/device:TPU:0, TPU, 17179869184, 5226438788282458354)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:8/device:TPU:1, TPU, 17179869184, 68249300334209851)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:8/device:TPU:2, TPU, 17179869184, 8524871710345371518)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:8/device:TPU:3, TPU, 17179869184, 17335212917621241024)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:8/device:TPU:4, TPU, 17179869184, 16007087871879047918)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:8/device:TPU:5, TPU, 17179869184, 10346801643648323827)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:8/device:TPU:6, TPU, 17179869184, 5675334305271002787)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:8/device:TPU:7, TPU, 17179869184, 8366757285664592560)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:8/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 17450198936577570389)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:8/device:XLA_CPU:0, XLA_CPU, 17179869184, 847017887281542582)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:9/device:CPU:0, CPU, -1, 1015665458983040413)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:9/device:TPU:0, TPU, 17179869184, 5021044810084586309)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:9/device:TPU:1, TPU, 17179869184, 3932771401775927291)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:9/device:TPU:2, TPU, 17179869184, 14479253135215890821)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:9/device:TPU:3, TPU, 17179869184, 10836258160956553624)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:9/device:TPU:4, TPU, 17179869184, 4884853066872305628)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:9/device:TPU:5, TPU, 17179869184, 5430713239014778649)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:9/device:TPU:6, TPU, 17179869184, 10904258856765794986)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:9/device:TPU:7, TPU, 17179869184, 9983771456140473152)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:9/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 13128540100515245854)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:9/device:XLA_CPU:0, XLA_CPU, 17179869184, 12047208506818775402)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:10/device:CPU:0, CPU, -1, 12460681008199218834)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:10/device:TPU:0, TPU, 17179869184, 68976981776577693)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:10/device:TPU:1, TPU, 17179869184, 8087348081697992214)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:10/device:TPU:2, TPU, 17179869184, 292871448457262341)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:10/device:TPU:3, TPU, 17179869184, 5941141233368976433)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:10/device:TPU:4, TPU, 17179869184, 392066189045991188)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:10/device:TPU:5, TPU, 17179869184, 13999399043917251966)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:10/device:TPU:6, TPU, 17179869184, 12177364256769124865)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:10/device:TPU:7, TPU, 17179869184, 5147642080525164214)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:10/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 7363559608327074551)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:10/device:XLA_CPU:0, XLA_CPU, 17179869184, 16897640633274096791)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:11/device:CPU:0, CPU, -1, 11089822050098038385)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:11/device:TPU:0, TPU, 17179869184, 11745043662331201666)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:11/device:TPU:1, TPU, 17179869184, 10859594890907689939)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:11/device:TPU:2, TPU, 17179869184, 15253099450570170932)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:11/device:TPU:3, TPU, 17179869184, 17770619485670091271)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:11/device:TPU:4, TPU, 17179869184, 18177252563582342568)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:11/device:TPU:5, TPU, 17179869184, 10588460704080248682)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:11/device:TPU:6, TPU, 17179869184, 17765178699929319775)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:11/device:TPU:7, TPU, 17179869184, 17535929439215353888)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:11/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 9402813760624285154)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:11/device:XLA_CPU:0, XLA_CPU, 17179869184, 5074250699076676978)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:12/device:CPU:0, CPU, -1, 9274973652862715903)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:12/device:TPU:0, TPU, 17179869184, 10084533768603547610)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:12/device:TPU:1, TPU, 17179869184, 13437266238724893627)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:12/device:TPU:2, TPU, 17179869184, 5784708408505396360)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:12/device:TPU:3, TPU, 17179869184, 1609170478150490493)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:12/device:TPU:4, TPU, 17179869184, 13509313542450969712)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:12/device:TPU:5, TPU, 17179869184, 14287333030460243447)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:12/device:TPU:6, TPU, 17179869184, 1719056036870218365)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:12/device:TPU:7, TPU, 17179869184, 13468308846015537150)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:12/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 5315441863058560879)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:12/device:XLA_CPU:0, XLA_CPU, 17179869184, 3598179642174791321)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:13/device:CPU:0, CPU, -1, 17570078876534001633)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:13/device:TPU:0, TPU, 17179869184, 15090332235212215250)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:13/device:TPU:1, TPU, 17179869184, 13899898502574839278)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:13/device:TPU:2, TPU, 17179869184, 7263499394466720980)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:13/device:TPU:3, TPU, 17179869184, 16974435948331981705)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:13/device:TPU:4, TPU, 17179869184, 6465098532330092471)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:13/device:TPU:5, TPU, 17179869184, 4043759619085714817)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:13/device:TPU:6, TPU, 17179869184, 16931065067642853123)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:13/device:TPU:7, TPU, 17179869184, 3498438448007893156)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:13/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 81375203753307607)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:13/device:XLA_CPU:0, XLA_CPU, 17179869184, 17055546581007735360)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:14/device:CPU:0, CPU, -1, 4480567260428186214)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:14/device:TPU:0, TPU, 17179869184, 68064799675058157)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:14/device:TPU:1, TPU, 17179869184, 4901403647054295614)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:14/device:TPU:2, TPU, 17179869184, 12194052005001991567)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:14/device:TPU:3, TPU, 17179869184, 17999258397697945484)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:14/device:TPU:4, TPU, 17179869184, 4720575518438360297)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:14/device:TPU:5, TPU, 17179869184, 13316465588089751491)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:14/device:TPU:6, TPU, 17179869184, 2862650944163238452)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:14/device:TPU:7, TPU, 17179869184, 12137176560798972517)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:14/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 8806332914250339147)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:14/device:XLA_CPU:0, XLA_CPU, 17179869184, 10210134545038733864)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:15/device:CPU:0, CPU, -1, 13749790342150132974)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:15/device:TPU:0, TPU, 17179869184, 3862833845704234130)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:15/device:TPU:1, TPU, 17179869184, 2869828432434130541)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:15/device:TPU:2, TPU, 17179869184, 15764204214674599810)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:15/device:TPU:3, TPU, 17179869184, 14242837718814737648)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:15/device:TPU:4, TPU, 17179869184, 4866323750944228611)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:15/device:TPU:5, TPU, 17179869184, 18140015470817044563)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:15/device:TPU:6, TPU, 17179869184, 9197479314939024589)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:15/device:TPU:7, TPU, 17179869184, 10071185415076015292)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:15/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 13003665764990147127)\n",
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:biomedbert/replica:0/task:15/device:XLA_CPU:0, XLA_CPU, 17179869184, 8216094093370364209)\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/jupyter/BioMedBERT/notebooks/bert/run_pretraining.py:405: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "WARNING:tensorflow:From /home/jupyter/BioMedBERT/notebooks/bert/run_pretraining.py:422: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:Found small feature: next_sentence_labels [1, 1]\n",
      "INFO:tensorflow:*** Features ***\n",
      "INFO:tensorflow:  name = input_ids, shape = (1, 128)\n",
      "INFO:tensorflow:  name = input_mask, shape = (1, 128)\n",
      "INFO:tensorflow:  name = masked_lm_ids, shape = (1, 20)\n",
      "INFO:tensorflow:  name = masked_lm_positions, shape = (1, 20)\n",
      "INFO:tensorflow:  name = masked_lm_weights, shape = (1, 20)\n",
      "INFO:tensorflow:  name = next_sentence_labels, shape = (1, 1)\n",
      "INFO:tensorflow:  name = segment_ids, shape = (1, 128)\n",
      "WARNING:tensorflow:From bert/modeling.py:172: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/modeling.py:410: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/modeling.py:491: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From bert/modeling.py:359: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From bert/modeling.py:672: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/jupyter/BioMedBERT/notebooks/bert/run_pretraining.py:157: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "INFO:tensorflow:**** Trainable Variables ****\n",
      "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (32000, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/predictions/transform/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/predictions/transform/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/predictions/transform/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/predictions/output_bias:0, shape = (32000,), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/seq_relationship/output_weights:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
      "INFO:tensorflow:  name = cls/seq_relationship/output_bias:0, shape = (2,), *INIT_FROM_CKPT*\n",
      "WARNING:tensorflow:From bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
      "\n",
      "WARNING:tensorflow:From bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "INFO:tensorflow:  total_loss = Tensor(\"add_2:0\", shape=(), dtype=float32)\n",
      "INFO:tensorflow:  learning_rate = 1e-05\n",
      "WARNING:tensorflow:From /home/jupyter/BioMedBERT/notebooks/bert/run_pretraining.py:167: The name tf.train.init_from_checkpoint is deprecated. Please use tf.compat.v1.train.init_from_checkpoint instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/jupyter/BioMedBERT/notebooks/bert/run_pretraining.py:168: The name tf.train.Scaffold is deprecated. Please use tf.compat.v1.train.Scaffold instead.\n",
      "\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:TPU job name biomedbert\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from gs://ekaba-assets/bert_model_10M/model.ckpt-3827500\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/training/saver.py:1069: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 3827500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:751: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
      "INFO:tensorflow:Installing graceful shutdown hook.\n",
      "INFO:tensorflow:Creating heartbeat manager for ['/job:biomedbert/replica:0/task:0/device:CPU:0', '/job:biomedbert/replica:0/task:1/device:CPU:0', '/job:biomedbert/replica:0/task:2/device:CPU:0', '/job:biomedbert/replica:0/task:5/device:CPU:0', '/job:biomedbert/replica:0/task:4/device:CPU:0', '/job:biomedbert/replica:0/task:6/device:CPU:0', '/job:biomedbert/replica:0/task:3/device:CPU:0', '/job:biomedbert/replica:0/task:7/device:CPU:0', '/job:biomedbert/replica:0/task:9/device:CPU:0', '/job:biomedbert/replica:0/task:10/device:CPU:0', '/job:biomedbert/replica:0/task:8/device:CPU:0', '/job:biomedbert/replica:0/task:11/device:CPU:0', '/job:biomedbert/replica:0/task:13/device:CPU:0', '/job:biomedbert/replica:0/task:14/device:CPU:0', '/job:biomedbert/replica:0/task:12/device:CPU:0', '/job:biomedbert/replica:0/task:15/device:CPU:0']\n",
      "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
      "\n",
      "INFO:tensorflow:Init TPU system\n",
      "INFO:tensorflow:Initialized TPU in 3 seconds\n",
      "INFO:tensorflow:Starting infeed thread controller.\n",
      "INFO:tensorflow:Starting outfeed thread controller.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Outfeed finished for iteration (0, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3830000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.5/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 2.587622, step = 3830000\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (1, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3832500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 1.9619888, step = 3832500 (69.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.8622\n",
      "INFO:tensorflow:examples/sec: 4590.36\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (2, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3835000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 2.9502106, step = 3835000 (61.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.3789\n",
      "INFO:tensorflow:examples/sec: 5168.5\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (3, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3837500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 1.4870306, step = 3837500 (69.068 sec)\n",
      "INFO:tensorflow:global_step/sec: 36.1962\n",
      "INFO:tensorflow:examples/sec: 4633.12\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (4, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3840000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.993949, step = 3840000 (63.741 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.2208\n",
      "INFO:tensorflow:examples/sec: 5020.26\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (5, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3842500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 5.030141, step = 3842500 (66.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.7778\n",
      "INFO:tensorflow:examples/sec: 4835.56\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (6, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3845000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 3.8402796, step = 3845000 (61.578 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.5988\n",
      "INFO:tensorflow:examples/sec: 5196.64\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (7, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3847500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 1.1050106, step = 3847500 (66.804 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.4229\n",
      "INFO:tensorflow:examples/sec: 4790.13\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (8, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3850000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 4.339951, step = 3850000 (62.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.0665\n",
      "INFO:tensorflow:examples/sec: 5128.51\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (9, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3852500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 1.8993055, step = 3852500 (62.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.2833\n",
      "INFO:tensorflow:examples/sec: 5156.26\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (10, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3855000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 2.152528, step = 3855000 (64.178 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.9539\n",
      "INFO:tensorflow:examples/sec: 4986.1\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (11, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3857500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "INFO:tensorflow:loss = 4.3912277, step = 3857500 (62.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.0437\n",
      "INFO:tensorflow:examples/sec: 5125.6\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (12, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3860000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.090067, step = 3860000 (64.172 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.9581\n",
      "INFO:tensorflow:examples/sec: 4986.64\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (13, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3862500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 2.48492, step = 3862500 (76.105 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.8492\n",
      "INFO:tensorflow:examples/sec: 4204.7\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (14, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3865000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 2.1478374, step = 3865000 (78.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 32.0168\n",
      "INFO:tensorflow:examples/sec: 4098.15\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (15, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3867500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 3.1862144, step = 3867500 (75.162 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.2616\n",
      "INFO:tensorflow:examples/sec: 4257.48\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (16, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3870000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 3.0867636, step = 3870000 (84.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 29.7315\n",
      "INFO:tensorflow:examples/sec: 3805.63\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (17, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3872500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 0.63149834, step = 3872500 (75.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.2662\n",
      "INFO:tensorflow:examples/sec: 4258.07\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (18, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3875000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.518549, step = 3875000 (70.685 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.3682\n",
      "INFO:tensorflow:examples/sec: 4527.13\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Outfeed finished for iteration (19, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3877500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 2.4233887, step = 3877500 (64.646 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.6723\n",
      "INFO:tensorflow:examples/sec: 4950.05\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (20, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3880000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 2.0737703, step = 3880000 (75.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 33.2792\n",
      "INFO:tensorflow:examples/sec: 4259.73\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (21, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3882500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.41143158, step = 3882500 (61.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.8892\n",
      "INFO:tensorflow:examples/sec: 5233.82\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (22, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3885000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.5756555, step = 3885000 (64.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.7137\n",
      "INFO:tensorflow:examples/sec: 4955.35\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (23, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3887500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.1738881, step = 3887500 (61.762 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.4784\n",
      "INFO:tensorflow:examples/sec: 5181.23\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (24, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3890000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.9660522, step = 3890000 (64.893 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.5245\n",
      "INFO:tensorflow:examples/sec: 4931.14\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Outfeed finished for iteration (25, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3892500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 0.8528185, step = 3892500 (65.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.1317\n",
      "INFO:tensorflow:examples/sec: 4880.86\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (26, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3895000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 2.1534355, step = 3895000 (63.225 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.5415\n",
      "INFO:tensorflow:examples/sec: 5061.32\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (27, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3897500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 2.5292623, step = 3897500 (61.697 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.5205\n",
      "INFO:tensorflow:examples/sec: 5186.62\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (28, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3900000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 2.4109843, step = 3900000 (62.766 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.8304\n",
      "INFO:tensorflow:examples/sec: 5098.29\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (29, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3902500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 3.6987884, step = 3902500 (62.320 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.1154\n",
      "INFO:tensorflow:examples/sec: 5134.77\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (30, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3905000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 2.8745627, step = 3905000 (63.891 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.1292\n",
      "INFO:tensorflow:examples/sec: 5008.54\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (31, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3907500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 4.156709, step = 3907500 (62.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.965\n",
      "INFO:tensorflow:examples/sec: 5115.52\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (32, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3910000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.880654, step = 3910000 (63.151 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.5877\n",
      "INFO:tensorflow:examples/sec: 5067.22\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (33, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3912500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.8864563, step = 3912500 (64.849 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.5512\n",
      "INFO:tensorflow:examples/sec: 4934.55\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (34, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3915000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.88420045, step = 3915000 (64.612 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.6927\n",
      "INFO:tensorflow:examples/sec: 4952.66\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Outfeed finished for iteration (35, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3917500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 3.1026113, step = 3917500 (64.321 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.8676\n",
      "INFO:tensorflow:examples/sec: 4975.06\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (36, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3920000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 2.8263526, step = 3920000 (62.664 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.8955\n",
      "INFO:tensorflow:examples/sec: 5106.62\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (37, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3922500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 5.7268443, step = 3922500 (65.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.3832\n",
      "INFO:tensorflow:examples/sec: 4913.05\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (38, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3925000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 2.6923058, step = 3925000 (66.824 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.4117\n",
      "INFO:tensorflow:examples/sec: 4788.7\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (39, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3927500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 2.5374994, step = 3927500 (61.644 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.5553\n",
      "INFO:tensorflow:examples/sec: 5191.08\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (40, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3930000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.4779938, step = 3930000 (64.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.7747\n",
      "INFO:tensorflow:examples/sec: 4963.16\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (41, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3932500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 1.3407971, step = 3932500 (73.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 34.0313\n",
      "INFO:tensorflow:examples/sec: 4356\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (42, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3935000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 2.1531775, step = 3935000 (62.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.9309\n",
      "INFO:tensorflow:examples/sec: 5111.16\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (43, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3937500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 2.6276438, step = 3937500 (62.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.1238\n",
      "INFO:tensorflow:examples/sec: 5135.85\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (44, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3940000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 4.954557, step = 3940000 (62.450 sec)\n",
      "INFO:tensorflow:global_step/sec: 40.0323\n",
      "INFO:tensorflow:examples/sec: 5124.13\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (45, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3942500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 3.3902528, step = 3942500 (63.583 sec)\n",
      "INFO:tensorflow:global_step/sec: 39.3189\n",
      "INFO:tensorflow:examples/sec: 5032.82\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (46, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3945000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:loss = 0.37142178, step = 3945000 (65.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.3615\n",
      "INFO:tensorflow:examples/sec: 4910.27\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (47, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3947500 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.61342597, step = 3947500 (64.658 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.665\n",
      "INFO:tensorflow:examples/sec: 4949.12\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (48, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n",
      "INFO:tensorflow:Saving checkpoints for 3950000 into gs://ekaba-assets/bert_model_10M/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.168008, step = 3950000 (64.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.8202\n",
      "INFO:tensorflow:examples/sec: 4968.99\n",
      "INFO:tensorflow:Enqueue next (2500) batch(es) of data to infeed.\n",
      "INFO:tensorflow:Dequeue next (2500) batch(es) of data from outfeed.\n",
      "INFO:tensorflow:Outfeed finished for iteration (49, 0)\n",
      "WARNING:tensorflow:TPUPollingThread found TPU b'for-shweta-tpu' in state READY, and health HEALTHY.\n"
     ]
    }
   ],
   "source": [
    "estimator.train(input_fn=train_input_fn, max_steps=TRAIN_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract pre-trained contextual embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !echo 'Who was Jim Henson ? ||| Jim Henson was a puppeteer' > ./input.txt #/tmp/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_TXT = 'input_fra.txt'\n",
    "OUTPUT_FILE = 'output_fra.jsonl'\n",
    "processes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XARGS_CMD = (\"python3 bert/extract_features.py \"\n",
    "             \"--input_file={} \"\n",
    "             \"--output_file={} \"\n",
    "             \"--vocab_file={} \"\n",
    "             \"--bert_config_file={} \"\n",
    "             \"--init_checkpoint={} \"\n",
    "             \"--layers=-1,-2,-3,-4 \"\n",
    "             \"--max_seq_length=128 \"\n",
    "             \"--batch_size=8 \")\n",
    "\n",
    "XARGS_CMD = XARGS_CMD.format(INPUT_TXT, OUTPUT_FILE, VOCAB_FILE,\n",
    "                             CONFIG_FILE, INIT_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!$XARGS_CMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 bert/extract_features.py --input_file='input.txt' --output_file='output.jsonl' --vocab_file=VOCAB_FILE --bert_config_file=bert_config --init_checkpoint=INIT_CHECKPOINT --layers=-1,-2,-3,-4 --max_seq_length=128 --batch_size=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biomedbert code extract embeddings \"input.txt\" \"vocabulary/ncbi/biomedbert-8M.txt\"\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BioMedBERT-Data-Analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
