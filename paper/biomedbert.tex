\documentclass{article}


\usepackage{arxiv}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{lipsum}
\usepackage{graphicx}
\graphicspath{ {./images/} }


\title{BioMedBERT: Language Model to Advance Discoverability for BioMedical Research}


\author{
% Ziyue Qi \\
%  School of Coumputing and Information\\
%  University of Pittsburgh\\
%  Pittsburgh, PA 15213 \\
%  \texttt{ziq2@pitt.edu} \\
%  %% examples of more authors
%   \And
% Zixuan Lu \\
%  School of Coumputing and Information\\
%  University of Pittsburgh\\
%  Pittsburgh, PA 15213 \\
%  \texttt{ZIL50@pitt.edu} \\
%  \And
% Yuchen Lu \\
%  School of Coumputing and Information\\
%  University of Pittsburgh\\
%  Pittsburgh, PA 15213 \\
%  \texttt{yul217@pitt.edu} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\begin{document}
\maketitle
\begin{abstract}
BioMedBERT advances the state-of-the-art language models for increased information discoverability from biomedical literature. The number of peer-reviewed papers that are published everyday is dramatically increasing. In addition, more papers are being published in pre-prints such as arXiv and biorXiv. PubMed reports that more than 1 million biomedical research papers are published each year, this amounts to about two papers per minute [1]. Since the 1st of January 2020 more than 8000 papers on COVID-19 have been published on PubMed. Our work leverages the BERT language model architecture to pre-train a large-scale BioMedical language representation model. 
\end{abstract}


% keywords can be removed
%\keywords{First keyword \and Second keyword \and More}


\section{Introduction}



\section{Related Work}


\section{Methodology}


\section{Results}


\section{Discussion}


\section{Conclusion}


\section{Acknowledgements}


\bibliographystyle{unsrt}  
\bibliography{references}  %%% Remove comment to use the external .bib file (using bibtex).
%%% and comment out the ``thebibliography'' section.


%%% Comment out this section when you \bibliography{references} is enabled.
%\begin{thebibliography}{1}
%
%\bibitem{kour2014real}
%George Kour and Raid Saabne.
%\newblock Real-time segmentation of on-line handwritten arabic script.
%\newblock In {\em Frontiers in Handwriting Recognition (ICFHR), 2014 14th
%  International Conference on}, pages 417--422. IEEE, 2014.
%
%\bibitem{kour2014fast}
%George Kour and Raid Saabne.
%\newblock Fast classification of handwritten on-line arabic characters.
%\newblock In {\em Soft Computing and Pattern Recognition (SoCPaR), 2014 6th
%  International Conference of}, pages 312--318. IEEE, 2014.
%
%\bibitem{hadash2018estimate}
%Guy Hadash, Einat Kermany, Boaz Carmeli, Ofer Lavi, George Kour, and Alon
%  Jacovi.
%\newblock Estimate and replace: A novel approach to integrating deep neural
%  networks with existing applications.
%\newblock {\em arXiv preprint arXiv:1804.09028}, 2018.

%\end{thebibliography}


\end{document}
